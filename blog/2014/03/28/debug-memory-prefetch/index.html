
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>memory prefetch浅析 - kk Blog —— 通用基础</title>

  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="kk Blog —— 通用基础" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <script src="/javascripts/category.js" type="text/javascript"></script>

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">kk Blog —— 通用基础</a></h1>
  
    <h2>慢慢搬迁中......</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
<li>
<form action="/search" method="get">
    <input class="search" name="query" type="text" placeholder="search..." x-webkit-speech />
    <input id="btnSubmit" value="search" type="submit">
</form>
</li>
  <li><a href="/atom.xml" rel="subscribe-rss">RSS</a></li>
  
</ul>
  
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h2 class="entry-title">memory prefetch浅析</h2>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2014-03-28T17:40:00+08:00'><span class='date'>2014-03-28</span> <span class='time'>17:40:00</span></time>
        
      </p>
    
  </header>


<div class="entry-content"><p>原文地址： <a href="http://www.searchtb.com/2014/03/memory-prefetch%e6%b5%85%e6%9e%90.html">http://www.searchtb.com/2014/03/memory-prefetch%e6%b5%85%e6%9e%90.html</a>  , 感谢原作者分享。</p>

<p>  最近在用vtune分析程序性能瓶颈时，发现一些内存访问的地方竟然成了cpu热点。经过仔细分析，发现这些热点主要是对大数组非连续位置的访问的引起的。比较消耗cpu的原因应该是 cache不命中。因为像这样局部性很差的内存访问逻辑，对cache是很不友好的。于是想到了prefetch……</p>

<p>  x86（以及其他很多体系结构）的CPU提供了prefetch系列指令，用于将指定地址的内存预取到cache。如”prefetcht0 (%rax)”将以$rax所保存的值为地址的内存所在的cache line（大小一般是64byte）载入每一级cache。</p>

<p>在适当位置加了prefetch之后，程序里相应的cpu热点果然得以消除，程序性能得到提升。</p>

<h4>现象</h4>

<p>在此也写一段测试程序，体验一下 prefetch的功效，并做一些简单的分析。（注，分析硬件的行为实在是一件痛苦的事情。对于软件来说，源代码摆在那里，一是一、二是二，很多问题都是 确定的。而硬件不仅看不到它的具体实现，也鲜有文档。并且相比操作系统为软件提供的虚拟而单纯的运行环境，硬件环境复杂多变，有时候实在让人难以琢磨。所 以以下分析实在难免存在谬误。不妥之处还请包涵。）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#include &lt;xmmintrin.h&gt;
</span><span class='line'>#include &lt;stdio.h&gt;
</span><span class='line'>#include &lt;stdlib.h&gt;
</span><span class='line'>#include &lt;unistd.h&gt;
</span><span class='line'>#include &lt;sys/mman.h&gt;
</span><span class='line'>#include &lt;sys/time.h&gt;
</span><span class='line'>#include &lt;sys/types.h&gt;
</span><span class='line'>#include &lt;sys/stat.h&gt;
</span><span class='line'>#include &lt;fcntl.h&gt;
</span><span class='line'>#include &lt;math.h&gt;
</span><span class='line'>void usage()
</span><span class='line'>{
</span><span class='line'>    printf("usage: BIN file step prefetch\n");
</span><span class='line'>    exit(1);
</span><span class='line'>}
</span><span class='line'>inline int calcu(int input)
</span><span class='line'>{
</span><span class='line'>#ifdef EMPTYCALC
</span><span class='line'>    return input;
</span><span class='line'>#endif
</span><span class='line'>    int val = (input % 99) * (input / 98);
</span><span class='line'>    val = val ? val : 1;
</span><span class='line'>#ifdef HEAVYCALC
</span><span class='line'>    double d = (double)input / (double)val;
</span><span class='line'>    return (int)pow(d, 1999.9);
</span><span class='line'>#endif
</span><span class='line'>    double n = sqrt(sqrt((double)(unsigned)input * 1.3));
</span><span class='line'>    double m = sqrt(sqrt((double)(unsigned)val * 0.9));
</span><span class='line'>    return (int)((double)input * (double)val * m / (n ? n : 1.1));
</span><span class='line'>}
</span><span class='line'>int run_withprefetch(const int *array, int size, int step, int prefetch)
</span><span class='line'>{
</span><span class='line'>    int result = 0;
</span><span class='line'>    printf("run with prefetch(%d)...\n", prefetch);
</span><span class='line'>    for (int i = 0; i &lt; step; i++) {
</span><span class='line'>        for (int j = i; j &lt; size; j += step) {
</span><span class='line'>            int k = j + step * prefetch;
</span><span class='line'>            if (k  &lt; size) {
</span><span class='line'>                _mm_prefetch(&array[k], _MM_HINT_T0);
</span><span class='line'>                //const int *addr = &array[k];
</span><span class='line'>                //__asm__ __volatile__ ("mov (%0), %%eax"::"r"(addr):"eax");
</span><span class='line'>                //__asm__ __volatile__ ("mov %0, %%eax"::"r"(k):"eax");
</span><span class='line'>            }
</span><span class='line'>            result += calcu(array[j]);
</span><span class='line'>        }
</span><span class='line'>    }
</span><span class='line'>    return result;
</span><span class='line'>}
</span><span class='line'>int run(const int *array, int size, int step)
</span><span class='line'>{
</span><span class='line'>    int result = 0;
</span><span class='line'>    printf("run...\n");
</span><span class='line'>    for (int i = 0; i &lt; step; i++) {
</span><span class='line'>        for (int j = i; j &lt; size; j += step) {
</span><span class='line'>            //asm volatile("lfence");
</span><span class='line'>            result += calcu(array[j]);
</span><span class='line'>        }
</span><span class='line'>    }
</span><span class='line'>    return result;
</span><span class='line'>}
</span><span class='line'>int main(int argc, const char *argv[])
</span><span class='line'>{
</span><span class='line'>    if (argc != 4) {
</span><span class='line'>        usage();
</span><span class='line'>    }
</span><span class='line'>    int step = atoi(argv[2]);
</span><span class='line'>    int prefetch = atoi(argv[3]);
</span><span class='line'>    int fd = open(argv[1], O_RDONLY);
</span><span class='line'>    if (fd == -1) {
</span><span class='line'>        usage();
</span><span class='line'>    }
</span><span class='line'>    struct stat st;
</span><span class='line'>    int ret = fstat(fd, &st);
</span><span class='line'>    if (ret != 0) {
</span><span class='line'>        usage();
</span><span class='line'>    }
</span><span class='line'>    int array_size = st.st_size / sizeof(int);
</span><span class='line'>    printf("array size: %d, step: %d. ", array_size, step);
</span><span class='line'>    const int *array = (const int *)mmap(NULL, st.st_size, PROT_READ, MAP_POPULATE|MAP_SHARED, fd, 0);
</span><span class='line'>    if (array == MAP_FAILED) {
</span><span class='line'>        usage();
</span><span class='line'>    }
</span><span class='line'>    struct timeval tv1, tv2;
</span><span class='line'>    gettimeofday(&tv1, NULL);
</span><span class='line'>    int result = 0;
</span><span class='line'>    if (prefetch == 0) {
</span><span class='line'>        result = run(array, array_size, step);
</span><span class='line'>    }
</span><span class='line'>    else if (prefetch &gt; 0) {
</span><span class='line'>        result = run_withprefetch(array, array_size, step, prefetch);
</span><span class='line'>    }
</span><span class='line'>    gettimeofday(&tv2, NULL);
</span><span class='line'>    tv2.tv_sec -= tv1.tv_sec;
</span><span class='line'>    tv2.tv_usec -= tv1.tv_usec;
</span><span class='line'>    if (tv2.tv_usec &lt; 0) {
</span><span class='line'>        tv2.tv_usec += 1000000;
</span><span class='line'>        tv2.tv_sec--;
</span><span class='line'>    }
</span><span class='line'>    printf("time cost: %d.%06d, ", tv2.tv_sec, tv2.tv_usec);
</span><span class='line'>    printf("result: %d\n", result);
</span><span class='line'>    return result;
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>程序mmap一个大文件（由file参数指定）作为大数组，对数组中的每一个元素进行一定的变换逻辑（calc函数，通过宏定义选择三种不同复杂度的逻辑）、然后加和。</p>

<p>对于数组元素的访问支持顺序访问和跳跃访问（step参数，跳跃间隙）、支持预取（prefetch参数，预取提前量）。</p>

<p>（注意，程序最终产生的result的值只跟选择的计算逻辑和输入文件的内容相关，跟读内存的顺序无关。所以，后续不管给程序加了什么稀奇古怪的读内存逻辑，最终的result都是一致的。这就确保了我们所加的各种读内存逻辑没有引入BUG。）</p>

<p>一些测试结果：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ ll -h test.tar.gz 
</span><span class='line'>-rw-rw-r-- 1 xiangy xiangy 1.8G Jun 27 09:37 test.tar.gz
</span><span class='line'>$ g++ -O2 prefetch.cpp -DHEAVYCALC -o prefetch.heavy
</span><span class='line'>$ g++ -O2 prefetch.cpp -DEMPTYCALC -o prefetch.empty
</span><span class='line'>$ g++ -O2 prefetch.cpp -o prefetch.normal
</span><span class='line'>$ ./prefetch.normal 
</span><span class='line'>usage: BIN file step prefetch</span></code></pre></td></tr></table></div></figure>


<p>（选择不同复杂度的计算逻辑，编译成以不同后缀命名的可执行文件。）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[case-1]$ ./prefetch.empty test.tar.gz 1024 0
</span><span class='line'>array size: 468787200, step: 1024. run...
</span><span class='line'>time cost: 23.980005, result: 692002678</span></code></pre></td></tr></table></div></figure>


<p>（空计算＋跳读内存。预期内存访问基本上都是cache miss，而计算逻辑基本上又不花时间，所以最终花费的时间主要就是读内存时间。记住这个值，下面的case经常需要参考它。）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[case-2]$ ./prefetch.normal test.tar.gz 1 0
</span><span class='line'>array size: 468787200, step: 1. run...
</span><span class='line'>time cost: 22.846302, result: 1309150882
</span><span class='line'>[case-3]$ ./prefetch.normal test.tar.gz 1024 0
</span><span class='line'>array size: 468787200, step: 1024. run...
</span><span class='line'>time cost: 66.041256, result: 1309150882
</span><span class='line'>[case-4]$ ./prefetch.normal test.tar.gz 1024 4
</span><span class='line'>array size: 468787200, step: 1024. run with prefetch(4)...
</span><span class='line'>time cost: 28.247350, result: 1309150882</span></code></pre></td></tr></table></div></figure>


<p>（以上是普通计算的运行情况。case-2顺序读内存预期基本上都是cache hit的，最终花费的时间主要是执行计算逻辑的时间；case-3跳读内存时间花费大量增加；case-4加了预取之后，时间花费基本上恢复到case-2的水平。)</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[case-5]$ ./prefetch.heavy test.tar.gz 1 0
</span><span class='line'>array size: 468787200, step: 1. run...
</span><span class='line'>time cost: 47.386533, result: 1625037789
</span><span class='line'>[case-6]$ ./prefetch.heavy test.tar.gz 1024 0
</span><span class='line'>array size: 468787200, step: 1024. run...
</span><span class='line'>time cost: 107.783801, result: 1625037789
</span><span class='line'>[case-7]$ ./prefetch.heavy test.tar.gz 1024 4
</span><span class='line'>array size: 468787200, step: 1024. run with prefetch(4)...
</span><span class='line'>time cost: 51.492479, result: 1625037789</span></code></pre></td></tr></table></div></figure>


<p>（以上是复杂计算的运行情况。跟前面的表现基本一致，跳读带来了大量的时间增长，而预取又基本恢复到顺序读时的水平。)</p>

<p>如果读内存开销很小、或者计算开销很小，prefetch也有用么？</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[case-8]$ ./prefetch.empty test.tar.gz 1024 4
</span><span class='line'>array size: 468787200, step: 1024. run with prefetch(4)...
</span><span class='line'>time cost: 24.253892, result: 692002678</span></code></pre></td></tr></table></div></figure>


<p>（空计算＋跳读内存，预取效果跟不加预取时差不多。）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[case-9]$ ./prefetch.normal test.tar.gz 1 4
</span><span class='line'>array size: 468787200, step: 1. run with prefetch(4)...
</span><span class='line'>time cost: 22.896790, result: 1309150882</span></code></pre></td></tr></table></div></figure>


<p>（普通计算＋顺序读内存＋预取，效果跟不加预取时也差不多。）</p>

<p>可见当读内存存在一定开销、且开销小于或相当于计算开销时，通过适当的prefetch能够将跳读内存开销隐藏掉，基本上达到顺序读内存的效果。</p>

<p>反过来如果计算开销不大、或者读内存本身没什么开销，单纯想通过prefetch来提升读内存的速度，效果并不明显。</p>

<h4>prefetch原理</h4>

<p>为什么prefetch能达到这样的效果呢？简单来说，prefetch将原本串行工作的计算过程和读内存过程并行化了。如：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>load-1                            load-1  
</span><span class='line'>calc-1                   =&gt;       calc-1    load-2  
</span><span class='line'>          load-2                            calc-2    load-3  
</span><span class='line'>          calc-2                                      calc-3  </span></code></pre></td></tr></table></div></figure>


<p>但是实际上却又并非如此简单。</p>

<p>在一个程序中，组成程序本身的指令虽然是有顺序的，但是CPU在执行指令的时候并不一定按部就班一条一条的去执行，指令之间有很多并行性可以去挖掘。（这就是所谓的ILP，Instruction Level Parallelism，指令级并行。）</p>

<p>两条指令想要并行执行需要满足三个条件：</p>

<p>1、指令之间没有数据依赖<br/>
如：a = b * 3; c = d + 5;， 就没有依赖；<br/>
如：a = b * 3; c = a + 5; ，“写后读”依赖。第二条指令需要a的值作为输入，而a的值依赖于第一条指令的计算结果；<br/>
如：a = b * 3; a = d + 5; ，“写后写”依赖。不过虽然第二条指令一定要在第一条指令修改a的值之后才能修改a的值（确保最终a的值是d + 5的结果），但是其实两条指令是可以并行执行的，最后将结果commit到a的时候再串行就OK了；<br/>
如：a = b * 3; b = d + 5;， “读后写”依赖。同样，虽然第二条指令一定不能在第一条指令读取b的值之前就将b的值修改（确保第一条指令读到的是旧值），但是只要确保第一条指令先拿到 b的旧值、或者直接跟生成b的旧值的那条指令关联上，之后两条指令还是可以并行执行的；</p>

<p>2、CPU功能部件充足<br/>
CPU中用来执行具体操作的功能部件是有限的，假设CPU只有一个乘法器。<br/>
如：a = b * 3; c = d + 5; ，一个使用乘法器、另一个使用加法器，互不影响就可以并行；<br/>
如：a = b * 3; c = d * 5; ，两条指令都需要使用这个仅有的乘法器，就只能串行了（当然也未必是第一条指令先占用乘法器，因为可能它所依赖的b的值尚未ready、而第二条指令所需要的d已经OK）；</p>

<p>3、CPU已经看到这两条指令<br/>
程序执行的指令序列可能无穷无尽（考虑 到有循环），CPU为了挖掘并行性不可能一下子分析所有指令，一定会有个限度。在经典的流水线算法－－tomasulo算法－－中，这个限度就是 RS（reservation station，保留站）的数目。CPU取指部件按指令顺序将指令放入RS，并设置它们的依赖关系（RS提供了这样的支持）。存在于RS中的指令当输入已 经ready、且需要的功能部件有空余时，便会开始执行。</p>

<p>遇到分支指令时指令序列如何确定呢？分支指令在执行完成之前根本就不知道程序要往哪里走。解决办法就是分支预测，根据一些统计信息猜测程序的走向。然后无视这些分支，就跟没有分支时一样去执行。如果分支预测错了，再回滚回来，按正确的序列重新执行。</p>

<p>回到我们的例子，每个loop有一个 load过程＋一个calc过程，calc过程依赖于load过程。但是下一次loop的load并不依赖于上一loop的calc过程，并且load和 calc使用不同的CPU功能部件，所以这两个过程是可以并行的。（for循环在经历很多次loop之后才会退出，每次分支的走向都是一样的，可以近似认 为分支预测一定成功。）</p>

<p>prefetch加与不加，前两个并行条件都是不会变的：prefetch既不会改变指令之间的依赖关系、也不会多占用或少占用CPU功能部件。但是为什么加上prefetch会有效果呢？</p>

<p>区别只在于第三个并行条件。试想当程序 执行到第N次loop时（loop-N），由于calc过程复杂，指令很多，RS一直被占满。直到计算进入尾声，loop-(N+1)的指令才进入RS， 这时CPU才知道要去load loop-(N+1)的input。而这些input在cache中不能命中，需要经历漫长的读内存过程，导致loop-(N+1)的calc指令卡在 RS中得不到执行。相当于load和calc过程被串行化了。</p>

<p>加了prefetch之后 呢？loop-(N+X)的prefetch指令排在loop-N的计算指令之前，早早的就能进入RS。这些load指令是计算的源头，其本身并没有依赖 别的数据，所以一旦内存通道空闲下来prefetch就可以开始工作了。于是load与calc才正真并行起来。</p>

<p>如下面示意：</p>

<p>case-2，顺序读内存，cache全命中：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>calc-11
</span><span class='line'>calc-12
</span><span class='line'>calc-13    calc-21
</span><span class='line'>           calc-22
</span><span class='line'>           calc-23    calc-31
</span><span class='line'>                      calc-32
</span><span class='line'>                      calc-33    calc-41
</span><span class='line'>                                 calc-42
</span><span class='line'>                                 calc-43    calc-51
</span><span class='line'>                                            calc-52
</span><span class='line'>                                            calc-53</span></code></pre></td></tr></table></div></figure>


<p>（每个loop约花费2个单位时间。）</p>

<p>case-3，跳读内存，cache全不命中：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>load-11
</span><span class='line'>load-12
</span><span class='line'>calc-11
</span><span class='line'>calc-12
</span><span class='line'>calc-13    load-21
</span><span class='line'>           load-22
</span><span class='line'>           calc-21
</span><span class='line'>           calc-22 
</span><span class='line'>           calc-23    load-31
</span><span class='line'>                      load-32
</span><span class='line'>                      calc-31
</span><span class='line'>                      calc-32
</span><span class='line'>                      calc-33</span></code></pre></td></tr></table></div></figure>


<p>（每个loop约花费4个单位时间。注，假设CPU执行到calc-N3的时候才看到有load-(N+1)1。）</p>

<p>case-4，跳读内存，加预取：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>load-11
</span><span class='line'>load-12
</span><span class='line'>calc-11    prefetch-21
</span><span class='line'>calc-12    prefetch-22
</span><span class='line'>calc-13    calc-21    prefetch-31
</span><span class='line'>           calc-22    prefetch-32
</span><span class='line'>           calc-23    calc-31    prefetch-41
</span><span class='line'>                      calc-32    prefetch-42
</span><span class='line'>                      calc-33    calc-41    prefetch-51
</span><span class='line'>                                 calc-42    prefetch-52
</span><span class='line'>                                 calc-43    calc-51
</span><span class='line'>                                            calc-52
</span><span class='line'>                                            calc-53</span></code></pre></td></tr></table></div></figure>


<p>（每个loop约花费2个单位时间。注，在calc-N1之前prefetch-(N+X)1就已经发起了。）</p>

<p>通过prefetch，使这些既耗时又 被后续指令依赖的load指令提前进入CPU的视野，让CPU可以利用可能空闲的内存带宽，提前完成读操作。另一方面，使用prefetch预取内存之 后，跟依赖于它的那些计算指令拉开了距离，使得计算指令不必等到马上就得使用load的输入时才临时抱佛脚。拉开相关依赖指令的距离正是编译器优化代码的 一种常用手段，通常通过指令重排调整无关指令的顺序来实现。</p>

<p>到这里prefetch的大致逻辑已经理清楚了，但是仔细想一下其实问题还很多……</p>

<h4>例子引出的问题</h4>

<p>第一个问题，为什么case-3（读内 存＋普通计算）的执行时间（66.041256）要比case-1（单纯的读内存）时间（23.980005）＋case-2（单纯的计算）时间 （22.846302）更长呢？按理说，就算load指令和calc指令完全串行，case-3的执行时间最多也就等于1、2之合吧。</p>

<p>这个问题应该可以用内存多通道来解释。 现在CPU访问内存的通道一般会有两个或以上。在case-1中，单纯的读内存其实并不代表串行的读内存。多个内存通道是可以让多个load指令并行工作 的，以充分利用内存带宽。而在case-3中，由于引入了一堆计算指令，导致RS被装满，CPU无法同时看到当前loop和下一个loop的load请 求，也就无法将两次load并行化。所以，更准确来说，case-3耗时这么长的原因并不是load与calc无法并行，而是load与load无法并 行。loop-N的calc过程跟loop-(N+1)的load过程是并行的，但是在loop-(N+1) load完成并进行calc之前，loop-(N+2)的load指令还未进入CPU的视野，所以无法与loop-(N+1)的load并行。</p>

<p>如何证实这一点呢？</p>

<p>我们在case-1中加一个lfence指令试试看。lfence是x86提供的内存屏障指令，作用是确保load操作的顺序：lfence之前的load操作必须先于lfence之后的load操作。如此便打破了load的并行性（如果真如刚才所说，并行性存在的话）。</p>

<p>修改run函数如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>int run(const int *array, int size, int step)
</span><span class='line'>{
</span><span class='line'>    int result = 0;
</span><span class='line'>    printf("run...\n");
</span><span class='line'>    for (int i = 0; i &lt; step; i++) {
</span><span class='line'>        for (int j = i; j &lt; size; j += step) {
</span><span class='line'>            asm volatile("lfence");
</span><span class='line'>            result += calcu(array[j]);
</span><span class='line'>        }
</span><span class='line'>    }
</span><span class='line'>    return result;
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>再次运行case-1：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[case-1.1]$ g++ -O2 prefetch.cpp -DEMPTYCALC
</span><span class='line'>[case-1.1]$ ./a.out test.tar.gz 1024 0
</span><span class='line'>array size: 468787200, step: 1024. run...
</span><span class='line'>time cost: 63.999864, result: 692002678</span></code></pre></td></tr></table></div></figure>


<p>（强制让load不能并行之后，case-1.1的耗时直接变成了case-3的水平。说明在原本的case-1中load是存在很大的并行度的。）</p>

<p>再以加lfence的代码运行一下case-6（未加prefetch、复杂计算）看看，如果在复杂计算＋跳读内存的情况下，读内存的并行性已经很少的话，加了lfence之后的耗时应该跟加之前差不多：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[case-6.1]$ g++ -O2 prefetch.cpp -DHEAVYCALC
</span><span class='line'>[case-6.1]$ ./a.out test.tar.gz 1024 0
</span><span class='line'>array size: 468787200, step: 1024. run...
</span><span class='line'>time cost: 114.787379, result: 1625037789</span></code></pre></td></tr></table></div></figure>


<p>（果然如此。）</p>

<p>还可以同时运行两个程序来看看是什么情 况。两个程序同时运行时，由于kernel load balance的作用，它们会尽量运行在不同的CPU上、且尽量不共享cache。那么，如果两个进程都总是能cache hit，则运行时间应该跟单个进程运行时差不多；反之如果总是cache miss，则两个进程会争抢内存带宽，运行时间会有所增加。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[case-2.2]$ ./prefetch.normal test.tar.gz 1 0 | ./prefetch.normal test.tar.gz 1 0
</span><span class='line'>array size: 468787200, step: 1. run...
</span><span class='line'>time cost: 22.964594, result: 1309150882</span></code></pre></td></tr></table></div></figure>


<p>（两个顺序读内存的普通计算一起运行，因为总是cache hit，所以跟单个运行的时间差不多。）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[case-1.2]$ ./a.out test.tar.gz 1024 0 | ./a.out test.tar.gz 1024 0
</span><span class='line'>array size: 468787200, step: 1024. run...
</span><span class='line'>time cost: 63.973557, result: 692002678</span></code></pre></td></tr></table></div></figure>


<p>（两个加了lfence的进程一起运行，由于进程内的内存访问已经串行化了，两个进程可以各自使用一个内存通道，所以运行时间跟单个进程运行时差不多。）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[case-1.3]$ ./prefetch.empty test.tar.gz 1024 0
</span><span class='line'>array size: 468787200, step: 1024. run...
</span><span class='line'>time cost: 24.083044, result: 692002678
</span><span class='line'>[case-1.4]$ ./prefetch.empty test.tar.gz 1024 0 | ./prefetch.empty test.tar.gz 1024 0
</span><span class='line'>array size: 468787200, step: 1024. run...
</span><span class='line'>time cost: 37.948864, result: 692002678</span></code></pre></td></tr></table></div></figure>


<p>（而用之前没加过lfence的程序再试一下，两个进程同时运行时，由于争抢内存带宽，运行时间就会受影响。）</p>

<h4>prefetch提前量</h4>

<p>还有一个问题也可以用内存多通道来解释，即prefetch提前量问题。先就之前的程序继续看几个case：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ for x in 1 2 4 8 16 32; do ./prefetch.normal test.tar.gz 1024 $x; done
</span><span class='line'>array size: 468787200, step: 1024. run with prefetch(1)...
</span><span class='line'>time cost: 36.262511, result: 1309150882
</span><span class='line'>array size: 468787200, step: 1024. run with prefetch(2)...
</span><span class='line'>time cost: 29.902517, result: 1309150882
</span><span class='line'>array size: 468787200, step: 1024. run with prefetch(4)...
</span><span class='line'>time cost: 28.052798, result: 1309150882
</span><span class='line'>array size: 468787200, step: 1024. run with prefetch(8)...
</span><span class='line'>time cost: 26.040215, result: 1309150882
</span><span class='line'>array size: 468787200, step: 1024. run with prefetch(16)...
</span><span class='line'>time cost: 26.198825, result: 1309150882
</span><span class='line'>array size: 468787200, step: 1024. run with prefetch(32)...
</span><span class='line'>time cost: 25.910506, result: 1309150882</span></code></pre></td></tr></table></div></figure>


<p>prefetch提前量从1增大到32。从结果看，当提前量小的时候，prefetch效果不明显。为什么呢？</p>

<p>假设提前量为1，那么loop-N会为 loop-(N+1)进行预取。但是从前面普通计算的数据可以看出，就一个loop而言，load的时间是多于calc时间的（从总量上说，load并行 之后才与calc时间相当，那么单独的load就应该比calc耗时长）。所以当执行到loop-(N+1)的时候，prefetch应该尚未完成。</p>

<p>再假设提前量为4，loop-N会为 loop-(N+4)做预取，loop-(N+1)为loop-(N+5)预取。而在进入loop-(N+1)时，loop-(N+4)的预取尚未完成， 而此时发起的loop-(N+5)的预取就能与之并行。可见增大提前量能更好的利用内存带宽。（虽然说以N为提前量就可以充分利用N个内存通道，但是机器 上还有kernel和其他进程也在使用内存，未必就能让你独占内存带宽。所以使用大于N的提前量更能充分利用空余的内存带宽。）</p>

<p>当然提前量肯定不能太大，否则等真正用到数据的时候，预取好的数据可能已经被从cache中挤出去了。</p>

<h4>用mov代替prefetch？</h4>

<p>prefetch指令可以用来预取，难道不用prefetch就不行了么？</p>

<p>我们将之前的run_withprefetch函数修改一下，把prefetch替换成简单的load操作：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>int run_withprefetch(const int *array, int size, int step, int prefetch)
</span><span class='line'>{
</span><span class='line'>    int result = 0;
</span><span class='line'>    printf("run with prefetch(%d)...\n", prefetch);
</span><span class='line'>    for (int i = 0; i &lt; step; i++) {
</span><span class='line'>        for (int j = i; j &lt; size; j += step) {
</span><span class='line'>            int k = j + step * prefetch;
</span><span class='line'>            if (k  &lt; size) {
</span><span class='line'>                const int *addr = &array[k];
</span><span class='line'>                asm volatile("mov (%0), %%eax"::"r"(addr):"eax");
</span><span class='line'>            }
</span><span class='line'>            result += calcu(array[j]);
</span><span class='line'>        }
</span><span class='line'>    }
</span><span class='line'>    return result;
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>重跑case-4：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[case-4.1]$ g++ -O2 prefetch.cpp
</span><span class='line'>[case-4.1]$ ./a.out test.tar.gz 1024 4
</span><span class='line'>array size: 468787200, step: 1024. run with prefetch(4)...
</span><span class='line'>time cost: 37.312423, result: 1309150882</span></code></pre></td></tr></table></div></figure>


<p>确实比不加prefetch的情况case-3（66.041256）要好很多，但还是比不上原来的case-4（28.247350）。</p>

<p>那么prefetch比直接movload好在哪里呢？<br/>
1、使用mov也同样能达到让load操作提前进入CPU视野的目的<br/>
2、使用mov访问过的内存同样会被cache住<br/>
3、仅仅是因为mov操作多占用了一个寄存器么？把代码改成这样看看（使用原来的prefetch但是多占用一个寄存器）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>if (k  &lt; size) {
</span><span class='line'>    _mm_prefetch(&array[k], _MM_HINT_T0);
</span><span class='line'>    __asm__ __volatile__ ("mov %0, %%eax"::"r"(k):"eax");
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>[case-4.2]$ g++ -O2 prefetch.cpp
</span><span class='line'>[case-4.2]$ ./a.out test.tar.gz 1024 4
</span><span class='line'>array size: 468787200, step: 1024. run with prefetch(4)...
</span><span class='line'>time cost: 28.051848, result: 1309150882</span></code></pre></td></tr></table></div></figure>


<p>可见仅仅多占用一个寄存器，貌似并没有什么影响。（在tomasulo算法中，这里实际上并没有多占用寄存器，而是多占用了RS。）</p>

<p>前面提到了tomasulo算法，提到了RS，这里面还有个东西叫ROB（reorder buffer，指令重排缓存）。前面还提到过对于“写后写”依赖指令，在执行过程中是可以并行的，只要保证最后写回的顺序不变就行了。ROB就能完成这个功能。</p>

<p>CPU取指令之后除了将其放入RS（让 其可以乱序执行），还要按顺序将其放入ROB。执行完成后的指令最终在ROB中排队，然后按顺序提交（将结果写回寄存器或内存）。ROB还有另一个很重要 的作用，就是分支预测失败时的回滚。分支指令也跟其他指令一样要在ROB中排队。如果分支指令执行完以后发现分支预测错了，则将ROB里排在这条分支之后 的指令及其结果都清理掉就行了。因为ROB是按指令顺序排队的，由于分支预测出错而被错误执行的那些指令一定都排在分支指令之后。</p>

<p>回到我们的例子，”mov (addr), %eax”这条指令会一直占着ROB，直到load完成。这将导致后续的指令结果一直得不到提交，尚未被CPU取走的指令又会因为无法获得ROB而不能被 取走。这又回到了类似于case-3（未加prefetch）的情形，指令无法大量进入CPU的视野，以致于内存访问无法占满内存带宽。只不过因为ROB 的资源没有RS那么紧张，所以阻塞的情况没有case-3那么严重。</p>

<p>基于以上说明，我们改造case-6（未加prefetch、复杂计算）看看。对于复杂计算，calc过程的指令更多，按理说，阻塞的情况会更严重，直接load应该效果更差。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[case-6.2]$ g++ -O2 prefetch.cpp -DHEAVYCALC
</span><span class='line'>[case-6.2]$ ./a.out test.tar.gz 1024 4
</span><span class='line'>array size: 468787200, step: 1024. run with prefetch(4)...
</span><span class='line'>time cost: 100.910547, result: 1625037789</span></code></pre></td></tr></table></div></figure>


<p>果然，这个结果比起原本的case-6（107.783801）已经没有优势了。</p>

<p>那么为什么prefetch不会受 ROB的大小限制呢？因为prefetch是一个特殊指令，没有输出，对程序上下文也没有影响，甚至于分支预测失败时也不需要回滚。那么CPU完全没必要 让prefetch指令进ROB（当然RS还是要进的，因为prefetch可能依赖于前面指令的结果）。</p>

<h4>其他问题 关于硬件prefetch</h4>

<p>虽然CPU提供了显式prefetch指令，其实它自己暗中也会进行一些prefetch，可以称之为硬件prefetch。</p>

<p>硬件prefetch有这么几个要点：<br/>
1、CPU在经历连续一定次数的cache miss后触发。偶尔发生的一次cache miss是很正常的，比如访问一个不常使用的全局变量；<br/>
2、CPU有一定的模式匹配策略，能够识别顺序访问和一些固定step的跳跃访问；<br/>
3、最重要的一点，硬件 prefetch不会跨page进行。因为内存是按page管理的，跨page意味着可能触发page fault，这是CPU自己所无法handle的，得由kernel来解决。CPU暗中的prefetch动作对软件来说本来是透明的，不能让 kernel去handle可能本不应发生的page fault，甚至于这样的page fault可能导致segment fault（相反，软件prefetch是软件自己发起的，有什么后果自己承担）；</p>

<p>基于第3点，CPU一般不会试图去识别 步长高于512字节的跳跃访问。因为要经历三次cache miss，CPU才能发现跳读内存的步长是相同的（pos2 – pos1 == pos3 – pos2），而后如果触发硬件prefetch的话，大于512字节的步长可能使得访存操作很快跨跃page边界，触发prefetch意义已经不大了。</p>

<p>我们可以继续用前面的程序来观察一下硬件prefetch的表现。将step从1到1024递增，不使用软件prefetch：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ for x in 1 2 4 8 16 32 64 128 256 512 1024; do ./prefetch.normal test.tar.gz $x 0; done
</span><span class='line'>array size: 468787200, step: 1. run...
</span><span class='line'>time cost: 22.863716, result: 1309150882
</span><span class='line'>array size: 468787200, step: 2. run...
</span><span class='line'>time cost: 23.438035, result: 1309150882
</span><span class='line'>array size: 468787200, step: 4. run...
</span><span class='line'>time cost: 23.846166, result: 1309150882
</span><span class='line'>array size: 468787200, step: 8. run...
</span><span class='line'>time cost: 24.171723, result: 1309150882
</span><span class='line'>array size: 468787200, step: 16. run...
</span><span class='line'>time cost: 25.502980, result: 1309150882
</span><span class='line'>array size: 468787200, step: 32. run...
</span><span class='line'>time cost: 37.461018, result: 1309150882
</span><span class='line'>array size: 468787200, step: 64. run...
</span><span class='line'>time cost: 39.829086, result: 1309150882
</span><span class='line'>array size: 468787200, step: 128. run...
</span><span class='line'>time cost: 44.291904, result: 1309150882
</span><span class='line'>array size: 468787200, step: 256. run...
</span><span class='line'>time cost: 65.332225, result: 1309150882
</span><span class='line'>array size: 468787200, step: 512. run...
</span><span class='line'>time cost: 64.764071, result: 1309150882
</span><span class='line'>array size: 468787200, step: 1024. run...
</span><span class='line'>time cost: 65.952260, result: 1309150882</span></code></pre></td></tr></table></div></figure>


<p>随着step的逐步增大，可以看出时间消耗分为三个档次：</p>

<p>step 1~16，cost 22~25，因为16个int是64byte，正好在一个cache line中。这么小的step再加上硬件预取基本上都能cache hit了；</p>

<p>step 32~128，cost 37~44，这个区间的cost跨度较大。在这些step下，单个page内读取值的个数分是32、16、8，硬件prefetch尚有一定的余地被触发、并发挥作用。然后随着可预取数目的减少，cost也不段增加；</p>

<p>step 256~，cost 64~65，步长超过了1024byte，硬件prefetch已经不会被触发；</p>

<h4>关于TLB cache miss</h4>

<p>应用程序中使用地址的都是虚拟地址，访问内存时存在虚拟地址到物理地址的转换过程。转换规则（即页表）是放在内存中的，并由TLB来cache。地址转换需要跳多级页表、多次读内存，所以如果TLB cache miss，代价是很大的。</p>

<p>不过在我的环境中貌似并不存在TLB cache miss的问题。继续改造程序验证一下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>int run(const int *array, int size, int step, int blocksize)
</span><span class='line'>{
</span><span class='line'>    int result = 0;
</span><span class='line'>    blocksize *= 4096;
</span><span class='line'>    if (blocksize == 0) {
</span><span class='line'>        blocksize = size;
</span><span class='line'>    }
</span><span class='line'>    printf("run... (block=%d pages)\n", blocksize/4096);
</span><span class='line'>    int start = 0;
</span><span class='line'>    int nsize = blocksize;
</span><span class='line'>    while (nsize == blocksize) {
</span><span class='line'>        if (start + blocksize &gt; size)
</span><span class='line'>            nsize = size - start;
</span><span class='line'>        for (int i = 0; i &lt; step; i+=32) {
</span><span class='line'>            for (int j = i; j &lt; nsize; j += step) {
</span><span class='line'>                int thissize = j + 32 &lt; nsize ? j + 32 : nsize;
</span><span class='line'>                for (int k = j; k &lt; thissize; k++) {
</span><span class='line'>                    result += calcu(array[start+k]);
</span><span class='line'>                }
</span><span class='line'>            }
</span><span class='line'>        }
</span><span class='line'>        start += nsize;
</span><span class='line'>    }
</span><span class='line'>    return result;
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>改造run函数把整个文件按blocksize划分成若干个块，每个块单独完成跳读逻辑。</p>

<p>于是，当块比较小时块内跳读时所涉及的page比较少，TLB应该能将相关的页表都cache住；而当块比较大，可能就会出现TLB cache miss。</p>

<p>这里面还存在另一个问题，按之前的做 法，每个int跳一次。如果块比较小，第一轮跳读时可能整个块都被cache了，后续的跳读都将cache hit。而块大时又无法cache整个块，后续的跳读又将继续cache miss。这就对观察TLB cache miss产生很大影响。所以程序改成每32个int跳读一次（按前面的结果，跳读32以后性能就不好了），以忽略cache hit所带来的影响。</p>

<p>修改main函数，用第4个参数来传递blocksize（0值表示不分block）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ for x in 128 256 512 1024 0; do ./a.out test.tar.gz 1024 $x; done
</span><span class='line'>array size: 468787200, step: 1024. run... (block=128 pages)
</span><span class='line'>time cost: 22.501363, result: 1309150882
</span><span class='line'>array size: 468787200, step: 1024. run... (block=256 pages)
</span><span class='line'>time cost: 22.627935, result: 1309150882
</span><span class='line'>array size: 468787200, step: 1024. run... (block=512 pages)
</span><span class='line'>time cost: 25.064514, result: 1309150882
</span><span class='line'>array size: 468787200, step: 1024. run... (block=1024 pages)
</span><span class='line'>time cost: 24.976720, result: 1309150882
</span><span class='line'>array size: 468787200, step: 1024. run... (block=114450 pages)
</span><span class='line'>time cost: 24.900870, result: 1309150882</span></code></pre></td></tr></table></div></figure>


<p>看起来TLB cache miss所带来的影响不大。</p>

<h4>关于L1 cache</h4>

<p>前面一直在讲cache，并没有细分是第几级的cache。其实前面的例子对内存的使用并没有那么精细，主要利用的cache还是L2 cache。</p>

<p>继续用前面分块的例子来看看，因为要考查cache，所以把连读32个int的逻辑去掉。run函数改造如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>int run(const int *array, int size, int step, int blocksize)
</span><span class='line'>{
</span><span class='line'>    int result = 0;
</span><span class='line'>    blocksize *= 4096;
</span><span class='line'>    if (blocksize == 0) {
</span><span class='line'>        blocksize = size;
</span><span class='line'>    }
</span><span class='line'>    printf("run... (block=%d pages)\n", blocksize/4096);
</span><span class='line'>    int start = 0;
</span><span class='line'>    int nsize = blocksize;
</span><span class='line'>    while (nsize == blocksize) {
</span><span class='line'>        if (start + blocksize &gt; size)
</span><span class='line'>            nsize = size - start;
</span><span class='line'>        for (int i = 0; i &lt; step; i++) {
</span><span class='line'>            for (int j = i; j &lt; nsize; j += step) {
</span><span class='line'>                result += calcu(array[start+j]);
</span><span class='line'>            }
</span><span class='line'>        }
</span><span class='line'>        start += nsize;
</span><span class='line'>    }
</span><span class='line'>    return result;
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>在一个块内反复跳读，如果以块的大小刚好能被cache住，则程序运行时间会很短；否则又得经历漫长的读内存过程。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ for x in 1 2 4 8 16 32 64 128 256 512 1024; do ./a.out test.tar.gz 1024 $x; done
</span><span class='line'>array size: 468787200, step: 1024. run... (block=1 pages)
</span><span class='line'>time cost: 1.614654, result: 692002678
</span><span class='line'>array size: 468787200, step: 1024. run... (block=2 pages)
</span><span class='line'>time cost: 1.554286, result: 692002678
</span><span class='line'>array size: 468787200, step: 1024. run... (block=4 pages)
</span><span class='line'>time cost: 1.625566, result: 692002678
</span><span class='line'>array size: 468787200, step: 1024. run... (block=8 pages)
</span><span class='line'>time cost: 2.621453, result: 692002678
</span><span class='line'>array size: 468787200, step: 1024. run... (block=16 pages)
</span><span class='line'>time cost: 2.697908, result: 692002678
</span><span class='line'>array size: 468787200, step: 1024. run... (block=32 pages)
</span><span class='line'>time cost: 2.724401, result: 692002678
</span><span class='line'>array size: 468787200, step: 1024. run... (block=64 pages)
</span><span class='line'>time cost: 2.710056, result: 692002678
</span><span class='line'>array size: 468787200, step: 1024. run... (block=128 pages)
</span><span class='line'>time cost: 3.864916, result: 692002678
</span><span class='line'>array size: 468787200, step: 1024. run... (block=256 pages)
</span><span class='line'>time cost: 4.241000, result: 692002678
</span><span class='line'>array size: 468787200, step: 1024. run... (block=512 pages)
</span><span class='line'>time cost: 20.216653, result: 692002678
</span><span class='line'>array size: 468787200, step: 1024. run... (block=1024 pages)
</span><span class='line'>time cost: 24.361176, result: 692002678</span></code></pre></td></tr></table></div></figure>


<p>随着block size的逐渐增大，程序运行时间显现出三个层次。分别代表着L1 cache hit（1〜4）、L2 cache hit（8〜256）、cache miss（512〜）三种状态。看起来L1 cache在本例中影响并不大。</p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">kk</span></span>

      




<time class='entry-date' datetime='2014-03-28T17:40:00+08:00'><span class='date'>2014-03-28</span> <span class='time'>17:40:00</span></time>
      

<span class="categories">
  
    <a class='category' href='/blog/cats/debug/'>debug</a>, <a class='category' href='/blog/cats/debug~base/'>base</a>
  
</span>


    </p>
    
      
    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2014/03/17/lang-c-const/" title="Previous Post: const的使用">&laquo; const的使用</a>
      
      
        <a class="basic-alignment right" href="/blog/2014/04/09/alg-suffix/" title="Next Post: [大牛的]后缀数组总结">[大牛的]后缀数组总结 &raquo;</a>
      
    </p>
  </footer>
</article>

</div>
<aside class="sidebar" id='load_sidebar'>
</aside>
<script type="text/javascript">
  $('#load_sidebar').load('/sidebar.html');
</script>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - kk -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
  <a title="Top" href="#" id="scroll2top" style="position: fixed; height: 50px; bottom: 50px; right: 30px; cursor: pointer; z-index: 9999; display: block; opacity: 1;"><img src="/images/scrollup.png"></a>
  <script src="/javascripts/scroll2top.js"></script>
  <script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1253604690'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s95.cnzz.com/z_stat.php%3Fid%3D1253604690' type='text/javascript'%3E%3C/script%3E"));</script>
</p>

</footer>
  





</body>
</html>
