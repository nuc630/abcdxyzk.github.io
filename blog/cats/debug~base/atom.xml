<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: debug~base | kk Blog —— 通用基础]]></title>
  <link href="http://abcdxyzk.github.io/blog/cats/debug~base/atom.xml" rel="self"/>
  <link href="http://abcdxyzk.github.io/"/>
  <updated>2016-11-08T23:51:40+08:00</updated>
  <id>http://abcdxyzk.github.io/</id>
  <author>
    <name><![CDATA[kk]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[ftrace 简介]]></title>
    <link href="http://abcdxyzk.github.io/blog/2016/03/28/debug-ftrace/"/>
    <updated>2016-03-28T16:29:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2016/03/28/debug-ftrace</id>
    <content type="html"><![CDATA[<p><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-ftrace/">https://www.ibm.com/developerworks/cn/linux/l-cn-ftrace/</a></p>

<h3>ftrace 简介</h3>

<p>ftrace 的作用是帮助开发人员了解 Linux 内核的运行时行为，以便进行故障调试或性能分析。</p>

<p>最早 ftrace 是一个 function tracer，仅能够记录内核的函数调用流程。如今 ftrace 已经成为一个 framework，采用 plugin 的方式支持开发人员添加更多种类的 trace 功能。</p>

<p>Ftrace 由 RedHat 的 Steve Rostedt 负责维护。到 2.6.30 为止，已经支持的 tracer 包括：</p>

<p>Function tracer 和 Function graph tracer: 跟踪函数调用。</p>

<p>Schedule switch tracer: 跟踪进程调度情况。</p>

<p>Wakeup tracer：跟踪进程的调度延迟，即高优先级进程从进入 ready 状态到获得 CPU 的延迟时间。该 tracer 只针对实时进程。</p>

<p>Irqsoff tracer：当中断被禁止时，系统无法相应外部事件，比如键盘和鼠标，时钟也无法产生 tick 中断。这意味着系统响应延迟，irqsoff 这个 tracer 能够跟踪并记录内核中哪些函数禁止了中断，对于其中中断禁止时间最长的，irqsoff 将在 log 文件的第一行标示出来，从而使开发人员可以迅速定位造成响应延迟的罪魁祸首。</p>

<p>Preemptoff tracer：和前一个 tracer 类似，preemptoff tracer 跟踪并记录禁止内核抢占的函数，并清晰地显示出禁止抢占时间最长的内核函数。</p>

<p>Preemptirqsoff tracer: 同上，跟踪和记录禁止中断或者禁止抢占的内核函数，以及禁止时间最长的函数。</p>

<p>Branch tracer: 跟踪内核程序中的 likely/unlikely 分支预测命中率情况。 Branch tracer 能够记录这些分支语句有多少次预测成功。从而为优化程序提供线索。</p>

<p>Hardware branch tracer：利用处理器的分支跟踪能力，实现硬件级别的指令跳转记录。在 x86 上，主要利用了 BTS 这个特性。</p>

<p>Initcall tracer：记录系统在 boot 阶段所调用的 init call 。</p>

<p>Mmiotrace tracer：记录 memory map IO 的相关信息。</p>

<p>Power tracer：记录系统电源管理相关的信息。</p>

<p>Sysprof tracer：缺省情况下，sysprof tracer 每隔 1 msec 对内核进行一次采样，记录函数调用和堆栈信息。</p>

<p>Kernel memory tracer: 内存 tracer 主要用来跟踪 slab allocator 的分配情况。包括 kfree，kmem_cache_alloc 等 API 的调用情况，用户程序可以根据 tracer 收集到的信息分析内部碎片情况，找出内存分配最频繁的代码片断，等等。</p>

<p>Workqueue statistical tracer：这是一个 statistic tracer，统计系统中所有的 workqueue 的工作情况，比如有多少个 work 被插入 workqueue，多少个已经被执行等。开发人员可以以此来决定具体的 workqueue 实现，比如是使用 single threaded workqueue 还是 per cpu workqueue.</p>

<p>Event tracer: 跟踪系统事件，比如 timer，系统调用，中断等。</p>

<p>这里还没有列出所有的 tracer，ftrace 是目前非常活跃的开发领域，新的 tracer 将不断被加入内核。</p>

<h3>ftrace 的使用</h3>

<p>ftrace 在内核态工作，用户通过 debugfs 接口来控制和使用 ftrace 。从 2.6.30 开始，ftrace 支持两大类 tracer：传统 tracer 和 Non-Tracer Tracer 。下面将分别介绍他们的使用。</p>

<h4>传统 Tracer 的使用</h4>

<p>使用传统的 ftrace 需要如下几个步骤：
<code>
    选择一种 tracer
    使能 ftrace
    执行需要 trace 的应用程序，比如需要跟踪 ls，就执行 ls
    关闭 ftrace
    查看 trace 文件
</code></p>

<p>用户通过读写 debugfs 文件系统中的控制文件完成上述步骤。使用 debugfs，首先要挂载她。命令如下：</p>

<pre><code>    # mkdir /debug 
    # mount -t debugfs nodev /debug
</code></pre>

<p>此时您将在 /debug 目录下看到 tracing 目录。 Ftrace 的控制接口就是该目录下的文件。</p>

<p>选择 tracer 的控制文件叫作 current_tracer 。选择 tracer 就是将 tracer 的名字写入这个文件，比如，用户打算使用 function tracer，可输入如下命令：
<code>
    # echo ftrace &gt; /debug/tracing/current_tracer
</code></p>

<p>文件 tracing_enabled 控制 ftrace 的开始和结束。
<code>
    # echo 1 &gt;/debug/tracing/tracing_enable
</code></p>

<p>上面的命令使能 ftrace 。同样，将 0 写入 tracing_enable 文件便可以停止 ftrace 。</p>

<p>ftrace 的输出信息主要保存在 3 个文件中。
<code>
    trace，该文件保存 ftrace 的输出信息，其内容可以直接阅读。
    latency_trace，保存与 trace 相同的信息，不过组织方式略有不同。主要为了用户能方便地分析系统中有关延迟的信息。
    trace_pipe 是一个管道文件，主要为了方便应用程序读取 trace 内容。算是扩展接口吧。
</code></p>

<p>下面详细解析各种 tracer 的输出信息。</p>

<h4>Function tracer 的输出</h4>

<p>Function tracer 跟踪函数调用流程，其 trace 文件格式如下：
<code>
     # tracer: function
     #
     #  TASK-PID   CPU#    TIMESTAMP        FUNCTION
     #   |  |       |          |                |
      bash-4251  [01]  10152.583854:    path_put &lt;-path_walk
      bash-4251  [01] 10152.583855: dput &lt;-path_put
      bash-4251  [01] 10152.583855: _atomic_dec_and_lock &lt;-dput
</code></p>

<p>可以看到，tracer 文件类似一张报表，前 4 行是表头。第一行显示当前 tracer 的类型。第三行是 header 。</p>

<p>对于 function tracer，该表将显示 4 列信息。首先是进程信息，包括进程名和 PID ；第二列是 CPU，在 SMP 体系下，该列显示内核函数具体在哪一个 CPU 上执行；第三列是时间戳；第四列是函数信息，缺省情况下，这里将显示内核函数名以及它的上一层调用函数。</p>

<p>通过对这张报表的解读，用户便可以获得完整的内核运行时流程。这对于理解内核代码也有很大的帮助。有志于精读内核代码的读者，或许可以考虑考虑 ftrace 。</p>

<p>如上例所示，path_walk() 调用了 path_put 。此后 path_put 又调用了 dput，进而 dput 再调用 _atomic_dec_and_lock 。</p>

<h4>Schedule switch tracer 的输出</h4>

<p>Schedule switch tracer 记录系统中的进程切换信息。在其输出文件 trace 中 , 输出行的格式有两种：</p>

<p>第一种表示进程切换信息：
<code>
    Context switches:
           Previous task              Next Task
      &lt;pid&gt;:&lt;prio&gt;:&lt;state&gt;  ==&gt;  &lt;pid&gt;:&lt;prio&gt;:&lt;state&gt;
</code></p>

<p>第二种表示进程 wakeup 的信息：
<code>
        Wake ups:
           Current task               Task waking up
      &lt;pid&gt;:&lt;prio&gt;:&lt;state&gt;    +  &lt;pid&gt;:&lt;prio&gt;:&lt;state&gt;
</code>
这里举一个实例：
<code>
     # tracer: sched_switch
     #
     #  TASK_PID   CPU#     TIMESTAMP             FUNCTION
     #     |         |            |                  |
       fon-6263  [000] 4154504638.932214:  6263:120:R +   2717:120:S
       fon-6263  [000] 4154504638.932214:  6263:120:? ==&gt; 2717:120:R
       bash-2717 [000] 4154504638.932214:  2717:120:S +   2714:120:S
</code></p>

<p>第一行表示进程 fon 进程 wakeup 了 bash 进程。其中 fon 进程的 pid 为 6263，优先级为 120，进程状态为 Ready 。她将进程 ID 为 2717 的 bash 进程唤醒。</p>

<p>第二行表示进程切换发生，从 fon 切换到 bash 。</p>

<h4>irqsoff tracer 输出</h4>

<p>有四个 tracer 记录内核在某种状态下最长的时延，irqsoff 记录系统在哪里关中断的时间最长； preemptoff/preemptirqsoff 以及 wakeup 分别记录禁止抢占时间最长的函数，或者系统在哪里调度延迟最长 (wakeup) 。这些 tracer 信息对于实时应用具有很高的参考价值。</p>

<p>为了更好的表示延迟，ftrace 提供了和 trace 类似的 latency_trace 文件。以 irqsoff 为例演示如何解读该文件的内容。</p>

<pre><code>     # tracer: irqsoff 
     irqsoff latency trace v1.1.5 on 2.6.26 
     -------------------------------------------------------------------- 
     latency: 12 us, #3/3, CPU#1 | (M:preempt VP:0, KP:0, SP:0 HP:0 #P:2) 
        ----------------- 
        | task: bash-3730 (uid:0 nice:0 policy:0 rt_prio:0) 
        ----------------- 
     =&gt; started at: sys_setpgid 
     =&gt; ended at:   sys_setpgid 
     #                _------=&gt; CPU# 
     #               / _-----=&gt; irqs-off 
     #              | / _----=&gt; need-resched 
     #              || / _---=&gt; hardirq/softirq 
     #              ||| / _--=&gt; preempt-depth 
     #              |||| / 
     #              |||||     delay 
     #  cmd     pid ||||| time  |   caller 
     #     \   /    |||||   \   |   / 
        bash-3730  1d...    0us : _write_lock_irq (sys_setpgid) 
        bash-3730  1d..1    1us+: _write_unlock_irq (sys_setpgid) 
        bash-3730  1d..2   14us : trace_hardirqs_on (sys_setpgid)
</code></pre>

<p>在文件的头部，irqsoff tracer 记录了中断禁止时间最长的函数。在本例中，函数 trace_hardirqs_on 将中断禁止了 12us 。</p>

<p>文件中的每一行代表一次函数调用。 Cmd 代表进程名，pid 是进程 ID 。中间有 5 个字符，分别代表了 CPU#，irqs-off 等信息，具体含义如下：</p>

<p>CPU# 表示 CPU ID ；</p>

<p>irqs-off 这个字符的含义如下：’ d ’表示中断被 disabled 。’ . ’表示中断没有关闭；</p>

<p>need-resched 字符的含义：’ N ’表示 need_resched 被设置，’ . ’表示 need-reched 没有被设置，中断返回不会进行进程切换；</p>

<p>hardirq/softirq 字符的含义 : &lsquo;H&rsquo; 在 softirq 中发生了硬件中断， &lsquo;h&rsquo; – 硬件中断，’ s ’表示 softirq，’ . ’不在中断上下文中，普通状态。</p>

<p>preempt-depth: 当抢占中断使能后，该域代表 preempt_disabled 的级别。</p>

<p>在每一行的中间，还有两个域：time 和 delay 。 time: 表示从 trace 开始到当前的相对时间。 Delay 突出显示那些有高延迟的地方以便引起用户注意。当其显示为 ! 时，表示需要引起注意。</p>

<h4>function graph tracer 输出</h4>

<p>Function graph tracer 和 function tracer 类似，但输出为函数调用图，更加容易阅读：</p>

<pre><code>     # tracer: function_graph 
     # 
     # CPU  OVERHEAD/DURATION      FUNCTION CALLS 
     # |     |   |                 |   |   |   | 
     0)               |  sys_open() { 
     0)               |    do_sys_open() { 
     0)               |      getname() { 
     0)               |        kmem_cache_alloc() { 
     0)   1.382 us    |          __might_sleep(); 
     0)   2.478 us    |        } 
     0)               |        strncpy_from_user() { 
     0)               |          might_fault() { 
     0)   1.389 us    |            __might_sleep(); 
     0)   2.553 us    |          } 
     0)   3.807 us    |        } 
     0)   7.876 us    |      } 
     0)                |      alloc_fd() { 
     0)   0.668 us    |        _spin_lock(); 
     0)   0.570 us    |        expand_files(); 
     0)   0.586 us    |        _spin_unlock();
</code></pre>

<p>OVERHEAD 为 ! 时提醒用户注意，该函数的性能比较差。上面的例子中可以看到 sys_open 调用了 do_sys_open，依次又调用了 getname()，依此类推。</p>

<h4>Sysprof tracer 的输出</h4>

<p>Sysprof tracer 定时对内核进行采样，她的输出文件中记录了每次采样时内核正在执行哪些内核函数，以及当时的内核堆栈情况。</p>

<p>每一行前半部分的格式和 3.1.1 中介绍的 function tracer 一样，只是，最后一部分 FUNCTION 有所不同。</p>

<p>Sysprof tracer 中，FUNCTION 列格式如下：
<code>
    Identifier  address frame_pointer/pid
</code></p>

<p>当 identifier 为 0 时，代表一次采样的开始，此时第三个数字代表当前进程的 PID ；</p>

<p>Identifier 为 1 代表内核态的堆栈信息；当 identifier 为 2 时，代表用户态堆栈信息；显示堆栈信息时，第三列显示的是 frame_pointer，用户可能需要打开 system map 文件查找具体的符号，这是 ftrace 有待改进的一个地方吧。</p>

<p>当 identifier 为 3 时，代表一次采样结束。</p>

<h3>Non-Tracer Tracer 的使用</h3>

<p>从 2.6.30 开始，ftrace 还支持几种 Non-tracer tracer，所谓 Non-tracer tracer 主要包括以下几种：
<code>
    Max Stack Tracer
    Profiling (branches / unlikely / likely / Functions)
    Event tracing
</code></p>

<p>和传统的 tracer 不同，Non-Tracer Tracer 并不对每个内核函数进行跟踪，而是一种类似逻辑分析仪的模式，即对系统进行采样，但似乎也不完全如此。无论怎样，这些 tracer 的使用方法和前面所介绍的 tracer 的使用稍有不同。下面我将试图描述这些 tracer 的使用方法。</p>

<h4>Max Stack Tracer 的使用</h4>

<p>这个 tracer 记录内核函数的堆栈使用情况，用户可以使用如下命令打开该 tracer：</p>

<pre><code>    # echo 1 &gt; /proc/sys/kernel/stack_tracer_enabled
</code></pre>

<p>从此，ftrace 便留心记录内核函数的堆栈使用。 Max Stack Tracer 的输出在 stack_trace 文件中：</p>

<pre><code>     # cat /debug/tracing/stack_trace 
     Depth Size Location (44 entries) 
     ----- ---- -------- 
     0) 3088 64 update_curr+0x64/0x136 
     1) 3024 64 enqueue_task_fair+0x59/0x2a1 
     2) 2960 32 enqueue_task+0x60/0x6b 
     3) 2928 32 activate_task+0x27/0x30 
     4) 2896 80 try_to_wake_up+0x186/0x27f 
    …
     42)  80 80 sysenter_do_call+0x12/0x32
</code></pre>

<p>从上例中可以看到内核堆栈最满的情况如下，有 43 层函数调用，堆栈使用大小为 3088 字节。此外还可以在 Location 这列中看到整个的 calling stack 情况。这在某些情况下，可以提供额外的 debug 信息，帮助开发人员定位问题。</p>

<h4>Branch tracer</h4>

<p>Branch tracer 比较特殊，她有两种模式，即是传统 tracer，又实现了 profiling tracer 模式。</p>

<p>作为传统 tracer 。其输出文件为 trace，格式如下：</p>

<pre><code>     # tracer: branch 
     # 
     #  TASK-PID   CPU#    TIMESTAMP        FUNCTION 
     #    |   |        |          |                | 
      Xorg-2491   [000] 688.561593: [ ok ] fput_light:file.h:29 
      Xorg-2491   [000] 688.561594: [ ok ] fput_light:file_table.c:330
</code></pre>

<p>在 FUNCTION 列中，显示了 4 类信息：</p>

<p>函数名，文件和行号，用中括号引起来的部分，显示了分支的信息，假如该字符串为 ok，表明 likely/unlikely 返回为真，否则字符串为 MISS 。举例来说，在文件 file.h 的第 29 行，函数 fput_light 中，有一个 likely 分支在运行时解析为真。我们看看 file.h 的第 29 行：</p>

<pre><code>    static inline void fput_light(struct file *file, int fput_needed) 
     {LINE29：    if (unlikely(fput_needed)) 
                      fput(file); 
     }
</code></pre>

<p>Trace 结果告诉我们，在 688 秒的时候，第 29 行代码被执行，且预测结果为 ok，即 unlikely 成功。</p>

<p>Branch tracer 作为 profiling tracer 时，其输出文件为 profile_annotated_branch，其中记录了 likely/unlikely 语句完整的统计结果。</p>

<pre><code>     #cat trace_stat/branch_ annotated 
     correct incorrect    %      function            file        line 
     ------- ----------  ---- ------------------ -------------- ----- 
     0      46             100   pre_schedule_rt    sched_rt.c     1449
</code></pre>

<p>下面是文件 sched_rt.c 的第 1449 行的代码：
<code>
    if (unlikely(rt_task(prev)) &amp;&amp; rq-&gt;rt.highest_prio.curr &gt; prev-&gt;prio)
        pull_rt_task(rq);
</code></p>

<p>记录表明，unlikely 在这里有 46 次为假，命中率为 100% 。假如为真的次数更多，则说明这里应该改成 likely 。</p>

<h4>Workqueue profiling</h4>

<p>假如您在内核编译时选中该 tracer，ftrace 便会统计 workqueue 使用情况。您只需使用下面的命令查看结果即可：
<code>
    # cat /debug/tracing/trace_stat/workqueue
</code></p>

<p>典型输出如下：</p>

<pre><code>     # CPU INSERTED  EXECUTED  NAME 
     #  |     |         |           | 
       0   38044    38044    events/0 
       0     426      426    khelper 
       0    9853     9853    kblockd/0 
       0       0        0    kacpid 
    …
</code></pre>

<p>可以看到 workqueue events 在 CPU 0 上有 38044 个 worker 被插入并执行。</p>

<h4>Event tracer</h4>

<p>Event t不间断地记录内核中的重要事件。用户可以用下面的命令查看 ftrace 支持的事件。</p>

<pre><code>    # cat /debug/tracing/available_event
</code></pre>

<p>下面以跟踪进程切换为例讲述 event tracer 的使用。首先打开 event tracer，并记录进程切换：</p>

<pre><code>    # echo sched:sched_switch &gt;&gt; /debug/tracing/set_event 
    # echo sched_switch &gt;&gt; /debug/tracing/set_event 
    # echo 1 &gt; /debug/tracing/events/sched/sched_switch/enable
</code></pre>

<p>上面三个命令的作用是一样的，您可以任选一种。</p>

<p>此时可以查看 ftrace 的输出文件 trace:</p>

<pre><code>     &gt;head trace 
     # tracer: nop 
     # 
     #   TASK-PID CPU#  TIMESTAMP FUNCTION 
     #    | |      |     |             | 
     &lt;idle&gt;-0 [000] 12093.091053: sched_switch: task swapper:0 [140] ==&gt; 
      /user/bin/sealer:2612 [120]
</code></pre>

<p>我想您会发现该文件很容易解读。如上例，表示一个进程切换 event，从 idle 进程切换到 sealer 进程。</p>

<hr />

<h2>ftrace 的实现</h2>

<p>研究 tracer 的实现是非常有乐趣的。理解 ftrace 的实现能够启发我们在自己的系统中设计更好的 trace 功能。</p>

<h3>ftrace 的整体构架</h3>

<p>Ftrace 的整体构架：
图 1. ftrace 组成</p>

<p><img src="/images/debug/2016-03-28.jpg" alt="" /></p>

<h3>ftrace 组成</h3>

<p>Ftrace 有两大组成部分，一是 framework，另外就是一系列的 tracer 。每个 tracer 完成不同的功能，它们统一由 framework 管理。 ftrace 的 trace 信息保存在 ring buffer 中，由 framework 负责管理。 Framework 利用 debugfs 系统在 /debugfs 下建立 tracing 目录，并提供了一系列的控制文件。</p>

<p>本文并不打算系统介绍 tracer 和 ftrace framework 之间的接口，只是打算从纯粹理论的角度，简单剖析几种具体 tracer 的实现原理。假如读者需要开发新的 tracer，可以参考某个 tracer 的源代码。
Function tracer 的实现</p>

<p>Ftrace 采用 GCC 的 profile 特性在所有内核函数的开始部分加入一段 stub 代码，ftrace 重载这段代码来实现 trace 功能。</p>

<p>gcc 的 -pg 选项将在每个函数入口处加入对 mcount 的调用代码。比如下面的 C 代码。
<code>
    //test.c
    void foo(void)
    {
        printf("foo");
    }
</code>
用 gcc 编译：</p>

<pre><code>    gcc -S test.c
</code></pre>

<p>反汇编如下：
清单 2. test.c 不加入 pg 选项的汇编代码</p>

<pre><code>    _foo: 
        pushl   %ebp 
        movl    %esp, %ebp 
        subl    $8, %esp 
        movl    $LC0, (%esp) 
        call    _printf 
        leave 
        ret
</code></pre>

<p>再加入 -gp 选项编译：
<code>
    gcc -pg -S test.c
</code></p>

<p>得到的汇编如下：
清单 3. test.c 加入 pg 选项后的汇编代码</p>

<pre><code>_foo: 
        pushl   %ebp 
        movl    %esp, %ebp 
        subl    $8, %esp 
 LP3: 
        movl    $LP3,%edx 
        call    _mcount 
        movl    $LC0, (%esp) 
        call    _printf 
        leave 
        ret
</code></pre>

<p>增加 pg 选项后，gcc 在函数 foo 的入口处加入了对 mcount 的调用：call _mcount 。原本 mcount 由 libc 实现，但您知道内核不会连接 libc 库，因此 ftrace 编写了自己的 mcount stub 函数，并借此实现 trace 功能。</p>

<p>在每个内核函数入口加入 trace 代码，必然会影响内核的性能，为了减小对内核性能的影响，ftrace 支持动态 trace 功能。</p>

<p>当 CONFIG_DYNAMIC_FTRACE 被选中后，内核编译时会调用一个 perl 脚本：recordmcount.pl 将每个函数的地址写入一个特殊的段：__mcount_loc</p>

<p>在内核初始化的初期，ftrace 查询 __mcount_loc 段，得到每个函数的入口地址，并将 mcount 替换为 nop 指令。这样在默认情况下，ftrace 不会对内核性能产生影响。</p>

<p>当用户打开 ftrace 功能时，ftrace 将这些 nop 指令动态替换为 ftrace_caller，该函数将调用用户注册的 trace 函数。其具体的实现在相应 arch 的汇编代码中，以 x86 为例，在 entry_32.s 中：
```
    ENTRY(ftrace_caller)
        cmpl $0, function_trace_stop
        jne  ftrace_stub
        pushl %eax
        pushl %ecx
        pushl %edx
        movl 0xc(%esp), %eax
        movl 0x4(%ebp), %edx
        subl $MCOUNT_INSN_SIZE, %eax
    .globl ftrace_call
    ftrace_call:
        call ftrace_stubline 10popl %edx
        popl %ecx
        popl %eax</p>

<pre><code>.globl ftrace_stub 
ftrace_stub: 
    ret 
END(ftrace_caller)
</code></pre>

<pre><code>
Function tracer 将 line10 这行代码替换为 function_trace_call() 。这样每个内核函数都将调用 function_trace_call() 。

在 function_trace_call() 函数内，ftrace 记录函数调用堆栈信息，并将结果写入 ring buffer，稍后，用户可以通过 debugfs 的 trace 文件读取该 ring buffer 中的内容。

### Irqsoff tracer 的实现

Irqsoff tracer 的实现依赖于 IRQ-Flags 。 IRQ-Flags 是 Ingo Molnar 维护的一个内核特性。使得用户能够在中断关闭和打开时得到通知，ftrace 重载了其通知函数，从而能够记录中断禁止时间。即，中断被关闭时，记录下当时的时间戳。此后，中断被打开时，再计算时间差，由此便可得到中断禁止时间。

IRQ-Flags 封装开关中断的宏定义：
</code></pre>

<pre><code>#define local_irq_enable() \ 
    do { trace_hardirqs_on (); raw_local_irq_enable(); } while (0)
</code></pre>

<pre><code>ftrace 在文件 ftrace_irqsoff.c 中重载了 trace_hardirqs_on 。具体代码不再罗列，主要是使用了 sched_clock（）函数来获得时间戳。

### hw-branch 的实现

Hw-branch 只在 IA 处理器上实现，依赖于 x86 的 BTS 功能。 BTS 将 CPU 实际执行到的分支指令的相关信息保存下来，即每个分支指令的源地址和目标地址。

软件可以指定一块 buffer，处理器将每个分支指令的执行情况写入这块 buffer，之后，软件便可以分析这块 buffer 中的功能。

Linux 内核的 DS 模块封装了 x86 的 BTS 功能。 Debug Support 模块封装了和底层硬件的接口，主要支持两种功能：Branch trace store(BTS) 和 precise-event based sampling (PEBS) 。 ftrace 主要使用了 BTS 功能。

### branch tracer 的实现

内核代码中常使用 likely 和 unlikely 提高编译器生成的代码质量。 Gcc 可以通过合理安排汇编代码最大限度的利用处理器的流水线。合理的预测是 likely 能够提高性能的关键，ftrace 为此定义了 branch tracer，跟踪程序中 likely 预测的正确率。

为了实现 branch tracer，重新定义了 likely 和 unlikely 。具体的代码在 compiler.h 中。
清单 6. likely/unlikely 的 trace 实现
</code></pre>

<pre><code> # ifndef likely 
 #  define likely(x) (__builtin_constant_p(x) ? !!(x) : __branch_check__(x, 1)) 
 # endif 
 # ifndef unlikely 
 #  define unlikely(x) (__builtin_constant_p(x) ? !!(x) : __branch_check__(x, 0)) 
 # endif
</code></pre>

<pre><code>
其中 __branch_check 的实现如下：
清单 7. _branch_check_ 的实现
</code></pre>

<pre><code>#define __branch_check__(x, expect) ({\ 
    int ______r;    \ 
    static struct ftrace_branch_data \ 
    __attribute__((__aligned__(4)))  \ 
    __attribute__((section("_ftrace_annotated_branch"))) \ 
                         ______f = { \ 
                           .func = __func__, \ 
                           .file = __FILE__, \ 
                           .line = __LINE__, \ 
                    }; \ 
              ______r = likely_notrace(x);\ 
              ftrace_likely_update(&amp;______f, ______r, expect); \ 
              ______r; \ 
  })
</code></pre>

<p>```</p>

<p>ftrace_likely_update() 将记录 likely 判断的正确性，并将结果保存在 ring buffer 中，之后用户可以通过 ftrace 的 debugfs 接口读取分支预测的相关信息。从而调整程序代码，优化性能。</p>

<hr />

<p><a href="http://blog.csdn.net/tommy_wxie/article/details/7340701">http://blog.csdn.net/tommy_wxie/article/details/7340701</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[debuginfo 编译速度]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/11/26/debug-spec/"/>
    <updated>2015-11-26T11:30:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/11/26/debug-spec</id>
    <content type="html"><![CDATA[<p>Have a look into /usr/lib/rpm/macros:
<code>
    #       Compression type and level for source/binary package payloads.
    #               "w9.gzdio"      gzip level 9 (default).
    #               "w9.bzdio"      bzip2 level 9.
    #               "w7.xzdio"      xz level 7, xz's default.
    #               "w7.lzdio"      lzma-alone level 7, lzma's default
    #
    #%_source_payload       w9.gzdio
    #%_binary_payload       w9.gzdio
</code></p>

<p>binkernel.spec中加入
<code>
    %_source_payload       w5.gzdio
    %_binary_payload       w5.gzdio
</code>
略微降低压缩率，大大提高打包速度。kernel增加600K，debuginfo增加3M，时间从14分钟降至2分钟内</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CC_STACKPROTECTOR防内核堆栈溢出补丁分析]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/11/17/debug-CC_STACKPROTECTOR/"/>
    <updated>2015-11-17T16:01:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/11/17/debug-CC_STACKPROTECTOR</id>
    <content type="html"><![CDATA[<p><a href="http://blog.aliyun.com/1126">http://blog.aliyun.com/1126</a></p>

<p>内核堆栈溢出通常有两种情况。一种是函数调用栈超出了内核栈THREAD_SIZE的大小， 这是栈底越界，另一种是栈上缓冲越界访问，这是栈顶越界。</p>

<h4>检测栈底越界</h4>

<p>以arm平台为例，内核栈THREAD_SIZE为8K,当调用栈层次过多或某调用栈上分配过大的 空间，就会导致它越界。越界后struct thread_info结构可能被破坏，轻则内核 panic，重则内核数据被覆盖仍继续运行。</p>

<h4>检测栈顶越界</h4>

<p>对于栈顶越界，gcc提供了支持。打开内核配置CONFIG_CC_STACKPROTECTOR后，会打 开编译选项-fstack-protector.</p>

<hr />

<p>  CC_STACKPROTECT补丁是Tejun Heo在09年给主线kernel提交的一个用来防止内核堆栈溢出的补丁。默认的config是将这个选项关闭的，可以在编译内核的时候， 修改.config文件为CONFIG_CC_STACKPROTECTOR=y来启用。未来飞天内核可以将这个选项开启来防止利用内核stack溢出的0day攻击。这个补丁的防溢出原理是： 在进程启动的时候， 在每个buffer的后面放置一个预先设置好的stack canary，你可以把它理解成一个哨兵， 当buffer发生缓冲区溢出的时候， 肯定会破坏stack canary的值， 当stack canary的值被破坏的时候， 内核就会直接当机。那么是怎么判断stack canary被覆盖了呢？ 其实这个事情是gcc来做的，内核在编译的时候给gcc加了个-fstack-protector参数， 我们先来研究下这个参数是做什么用的。</p>

<p>先写个简单的有溢出的程序：</p>

<pre><code>    [wzt@localhost csaw]$ cat test.c

    #include &lt;stdio.h&gt;
    #include &lt;stdlib.h&gt;

    void test(void)
    {
        char buff[64];

        memset(buff, 0x41, 128);     //向64大小的buffer拷贝128字节， 肯定会发生缓冲区溢出。
    }

    int main(void)
    {
        test();

        return 0;
    }
</code></pre>

<pre><code>    [wzt@localhost csaw]$ gcc -o test test.c
    [wzt@localhost csaw]$ ./test
    段错误
</code></pre>

<p>反汇编看看：</p>

<pre><code>    [wzt@localhost csaw]$ objdump -d test &gt; hex

    08048384 &lt;test&gt;:
     8048384:       55                      push   %ebp
     8048385:       89 e5                   mov    %esp,%ebp
     8048387:       83 ec 58                sub    $0x58,%esp
     804838a:       c7 44 24 08 80 00 00    movl   $0x80,0x8(%esp)
     8048391:       00
     8048392:       c7 44 24 04 41 00 00    movl   $0x41,0x4(%esp)
     8048399:       00
     804839a:       8d 45 c0                lea    0xffffffc0(%ebp),%eax
     804839d:       89 04 24                mov    %eax,(%esp)
     80483a0:       e8 e3 fe ff ff          call   8048288 &lt;memset@plt&gt;
     80483a5:       c9                      leave
     80483a6:       c3                      ret
</code></pre>

<p>没什么特别的，我们在加上-fstack-protector参数看看：</p>

<pre><code>    [wzt@localhost csaw]$ gcc -o test test.c -fstack-protector
    [wzt@localhost csaw]$ ./test
    *** stack smashing detected ***: ./test terminated
    已放弃
</code></pre>

<p>这次程序打印了一条堆栈被溢出的信息，然后就自动退出了。</p>

<p>在反汇编看下：</p>

<pre><code>    [wzt@localhost csaw]$ objdump -d test &gt; hex1

    080483d4 &lt;test&gt;:
     80483d4:       55                      push   %ebp
     80483d5:       89 e5                   mov    %esp,%ebp
     80483d7:       83 ec 68                sub    $0x68,%esp
     80483da:       65 a1 14 00 00 00       mov    %gs:0x14,%eax
     80483e0:       89 45 fc                mov    %eax,0xfffffffc(%ebp)
     80483e3:       31 c0                   xor    %eax,%eax
     80483e5:       c7 44 24 08 80 00 00    movl   $0x80,0x8(%esp)
     80483ec:       00
     80483ed:       c7 44 24 04 41 00 00    movl   $0x41,0x4(%esp)
     80483f4:       00
     80483f5:       8d 45 bc                lea    0xffffffbc(%ebp),%eax
     80483f8:       89 04 24                mov    %eax,(%esp)
     80483fb:       e8 cc fe ff ff          call   80482cc &lt;memset@plt&gt;
     8048400:       8b 45 fc                mov    0xfffffffc(%ebp),%eax
     8048403:       65 33 05 14 00 00 00    xor    %gs:0x14,%eax
     804840a:       74 05                   je     8048411 &lt;test+0x3d&gt;
     804840c:       e8 db fe ff ff          call   80482ec &lt;__stack_chk_fail@plt&gt;
     8048411:       c9                      leave
     8048412:       c3                      ret
</code></pre>

<p>使用-fstack-protector参数后， gcc在函数的开头放置了几条汇编代码：</p>

<pre><code>     80483d7:       83 ec 68                sub    $0x68,%esp
     80483da:       65 a1 14 00 00 00       mov    %gs:0x14,%eax
     80483e0:       89 45 fc                mov    %eax,0xfffffffc(%ebp)
</code></pre>

<p>将代码段gs偏移0×14内存处的值赋值给了ebp-4， 也就是第一个变量值的后面。</p>

<p>在call完memeset后，有如下汇编代码：</p>

<pre><code>     80483fb:       e8 cc fe ff ff          call   80482cc &lt;memset@plt&gt;
     8048400:       8b 45 fc                mov    0xfffffffc(%ebp),%eax
     8048403:       65 33 05 14 00 00 00    xor    %gs:0x14,%eax
     804840a:       74 05                   je     8048411 &lt;test+0x3d&gt;
     804840c:       e8 db fe ff ff          call   80482ec &lt;__stack_chk_fail@plt&gt;
</code></pre>

<p>在memset后，gcc要检查这个操作是否发生了堆栈溢出, 将保存在ebp-4的这个值与原来的值对比一下，如果不相同， 说明堆栈发生了溢出，那么就会执行stack_chk_fail这个函数， 这个函数是glibc实现的，打印出上面看到的信息， 然后进程退出。</p>

<p>从这个例子中我们可以看出gcc使用了-fstack-protector参数后，会自动检查堆栈是否发生了溢出， 但是有一个前提就是内核要给每个进程提前设置好一个检测值放置在%gs:0×14位置处，这个值称之为stack canary。所以我们可以看到防止堆栈溢出是由内核和gcc共同来完成的。</p>

<p>gcc的任务就是放置几条汇编代码， 然后和%gs:0×14位置处的值进行对比即可。 主要任务还是内核如何来设置stack canary， 也是CC_STACKPROTECTOR补丁要实现的目的， 下面我们仔细来看下这个补丁是如何实现的。</p>

<p>既然gcc硬性规定了stack canary必须在%gs的某个偏移位置处， 那么内核也必须按着这个规定来设置。</p>

<p>对于32位和64位内核， gs寄存器有着不同的功能。</p>

<p>64位内核gcc要求stack canary是放置在gs段的40偏移处， 并且gs寄存器在每cpu变量中是共享的，每cpu变量irq_stack_union的结构如下：</p>

<pre><code>    arch/x86/include/asm/processor.h

    union irq_stack_union {
        char irq_stack[IRQ_STACK_SIZE];
        /*
         * GCC hardcodes the stack canary as %gs:40.  Since the
         * irq_stack is the object at %gs:0, we reserve the bottom
         * 48 bytes of the irq stack for the canary. 
         */
        struct {
            char gs_base[40];
            unsigned long stack_canary;
        };
    };

    DECLARE_PER_CPU_FIRST(union irq_stack_union, irq_stack_union);
</code></pre>

<p>gs_base只是一个40字节的站位空间， stack_canary就紧挨其后。并且在应用程序进出内核的时候，内核会使用swapgs指令自动更换gs寄存器的内容。</p>

<p>32位下就稍微有点复杂了。由于某些处理器在加载不同的段寄存器时很慢， 所以内核使用fs段寄存器替换了gs寄存器。 但是gcc在使用-fstack-protector的时候， 还要用到gs段寄存器， 所以内核还要管理gs寄存器，我们要把CONFIG_X86_32_LAZY_GS选项关闭， gs也只在进程切换的时候才改变。 32位用每cpu变量stack_canary保存stack canary。</p>

<pre><code>    struct stack_canary {
        char __pad[20];         /* canary at %gs:20 */
        unsigned long canary;
    };      
    DECLARE_PER_CPU_ALIGNED(struct stack_canary, stack_canary);
</code></pre>

<p>内核是处于保护模式的， 因此gs寄存器就变成了保护模式下的段选子，在GDT表中也要有相应的设置：</p>

<pre><code>    diff --git a/arch/x86/include/asm/segment.h b/arch/x86/include/asm/segment.h
    index 1dc1b51..14e0ed8 100644 (file)
    --- a/arch/x86/include/asm/segment.h
    +++ b/arch/x86/include/asm/segment.h
    @@ -61,7 +61,7 @@
      *
      *  26 - ESPFIX small SS
      *  27 - per-cpu                       [ offset to per-cpu data area ]
    - *  28 - unused
    + *  28 - stack_canary-20               [ for stack protector ]
      *  29 - unused
      *  30 - unused
      *  31 - TSS for double fault handler
    @@ -95,6 +95,13 @@
     #define __KERNEL_PERCPU 0
     #endif

    +#define GDT_ENTRY_STACK_CANARY         (GDT_ENTRY_KERNEL_BASE + 16)
    +#ifdef CONFIG_CC_STACKPROTECTOR
    +#define __KERNEL_STACK_CANARY          (GDT_ENTRY_STACK_CANARY * 8)
    +#else
    +#define __KERNEL_STACK_CANARY          0
    +#endif
    +
     #define GDT_ENTRY_DOUBLEFAULT_TSS      31
</code></pre>

<p>GDT表中的第28个表项用来定为stack canary所在的段。</p>

<pre><code>    #define GDT_STACK_CANARY_INIT                                           \
            [GDT_ENTRY_STACK_CANARY] = GDT_ENTRY_INIT(0x4090, 0, 0x18),
</code></pre>

<p>GDT_STACK_CANARY_INIT在刚进入保护模式的时候被调用， 这个段描述符项被设置为基地址为0， 段大小设为24，因为只在基地址为0， 偏移为0×14处放置一个4bytes的stack canary， 所以24字节正好。不理解的同学可以看看intel保护模式的手册， 对着段描述符结构一个个看就行了。</p>

<p>在进入保护模式后， start_kernel()会调用boot_init_stack_canary()来初始话一个stack canary。</p>

<pre><code>    /*      
     * Initialize the stackprotector canary value.
     *
     * NOTE: this must only be called from functions that never return,
     * and it must always be inlined.
     */
    static __always_inline void boot_init_stack_canary(void)
    {
        u64 canary;
        u64 tsc;

    #ifdef CONFIG_X86_64
        BUILD_BUG_ON(offsetof(union irq_stack_union, stack_canary) != 40);
    #endif
        /*
         * We both use the random pool and the current TSC as a source
         * of randomness. The TSC only matters for very early init,
         * there it already has some randomness on most systems. Later
         * on during the bootup the random pool has true entropy too.
         */
        get_random_bytes(&amp;canary, sizeof(canary));
        tsc = __native_read_tsc();
        canary += tsc + (tsc &lt;&lt; 32UL);

        current-&gt;stack_canary = canary;
    #ifdef CONFIG_X86_64
        percpu_write(irq_stack_union.stack_canary, canary);
    #else
        percpu_write(stack_canary.canary, canary);
    #endif
    }
</code></pre>

<p>随机出了一个值赋值给每cpu变量， 32位是stack_canary, 64位是irq_stack_union。</p>

<p>内核在进一步初始化cpu的时候，会调用setup_stack_canary_segment()来设置每个cpu的GDT的stack canary描述符项：</p>

<p>start_kernel()->setup_per_cpu_areas()->setup_stack_canary_segment：</p>

<pre><code>    static inline void setup_stack_canary_segment(int cpu)
    {
    #ifdef CONFIG_X86_32
        unsigned long canary = (unsigned long)&amp;per_cpu(stack_canary, cpu);
        struct desc_struct *gdt_table = get_cpu_gdt_table(cpu);
        struct desc_struct desc;

        desc = gdt_table[GDT_ENTRY_STACK_CANARY];
        set_desc_base(&amp;desc, canary);
        write_gdt_entry(gdt_table, GDT_ENTRY_STACK_CANARY, &amp;desc, DESCTYPE_S);
    #endif
    }
</code></pre>

<p>在内核刚进入保护模式的时候, stack canary描述符的基地址被初始化为0， 现在在cpu初始化的时候要重新设置为每cpu变量stack_canary的地址， 而不是变量保存的值。通过这些设置当内核代码在访问%gs:0×14的时候， 就会访问stack canry保存的值。注意：setup_stack_canary_segment是针对32位内核做设置， 因为64位内核中的irq_stack_union是每cpu共享的， 不用针对每个cpu单独设置。 然后就可以调用switch_to_new_gdt(cpu);来加载GDT表和加载gs寄存器。</p>

<p>经过上述初始化过程，在内核代码里访问%gs:0×14就可以定位stack canary的值了， 那么每个进程的stack canary是什么时候设置的呢？</p>

<p>在内核启动一个进程的时候， 会把gs寄存器的值设为KERNEL_STACK_CANARY</p>

<pre><code>    --- a/arch/x86/kernel/process_32.c
    +++ b/arch/x86/kernel/process_32.c
    @@ -212,6 +212,7 @@ int kernel_thread(int (*fn)(void *), void *arg, unsigned long flags)
            regs.ds = __USER_DS;
            regs.es = __USER_DS;
            regs.fs = __KERNEL_PERCPU;
    +       regs.gs = __KERNEL_STACK_CANARY;
            regs.orig_ax = -1;
            regs.ip = (unsigned long) kernel_thread_helper;
            regs.cs = __KERNEL_CS | get_kernel_rpl();
</code></pre>

<p>内核在fork一个进程的时候， 有如下操作：</p>

<pre><code>    static struct task_struct *dup_task_struct(struct task_struct *orig)
    {
    #ifdef CONFIG_CC_STACKPROTECTOR
        tsk-&gt;stack_canary = get_random_int();
    #endif
    }
</code></pre>

<p>随机初始化了一个stack_canary保存在task_struct结构中的stack_canary变量中。当进程在切换的时候， 通过switch宏把新进程的stack canary保存在每cpu变量stack_canary中， 当前进程的stack_canary也保存在一个每cpu变量中，完成stack canary的切换。</p>

<pre><code>    diff --git a/arch/x86/include/asm/system.h b/arch/x86/include/asm/system.h
    index 79b98e5..2692ee8 100644 (file)
    --- a/arch/x86/include/asm/system.h
    +++ b/arch/x86/include/asm/system.h
    @@ -23,6 +23,22 @@ struct task_struct *__switch_to(struct task_struct *prev,

     #ifdef CONFIG_X86_32

    +#ifdef CONFIG_CC_STACKPROTECTOR
    +#define __switch_canary                                                \
    +       "movl "__percpu_arg([current_task])",%%ebx\n\t"                 \
    +       "movl %P[task_canary](%%ebx),%%ebx\n\t"                         \
    +       "movl %%ebx,"__percpu_arg([stack_canary])"\n\t"
    +#define __switch_canary_oparam                                         \
    +       , [stack_canary] "=m" (per_cpu_var(stack_canary))
    +#define __switch_canary_iparam                                         \
    +       , [current_task] "m" (per_cpu_var(current_task))                \
    +       , [task_canary] "i" (offsetof(struct task_struct, stack_canary))
    +#else  /* CC_STACKPROTECTOR */
    +#define __switch_canary
    +#define __switch_canary_oparam
    +#define __switch_canary_iparam
    +#endif /* CC_STACKPROTECTOR */
    +
     /*
      * Saving eflags is important. It switches not only IOPL between tasks,
      * it also protects other tasks from NT leaking through sysenter etc.
    @@ -46,6 +62,7 @@ do {                                                  \
                         "pushl %[next_ip]\n\t"     /* restore EIP   */     \
                         "jmp __switch_to\n"        /* regparm call  */     \
                         "1:\t"                                             \
    +                    __switch_canary                                    \
                         "popl %%ebp\n\t"           /* restore EBP   */     \
                         "popfl\n"                  /* restore flags */     \
                                                                            \
    @@ -58,6 +75,8 @@ do {                                                  \
                           "=b" (ebx), "=c" (ecx), "=d" (edx),              \
                           "=S" (esi), "=D" (edi)                           \
                                                                            \
    +                      __switch_canary_oparam                           \
    +                                                                       \
                           /* input parameters: */                          \
                         : [next_sp]  "m" (next-&gt;thread.sp),                \
                           [next_ip]  "m" (next-&gt;thread.ip),                \
    @@ -66,6 +85,8 @@ do {                                                  \
                           [prev]     "a" (prev),                           \
                           [next]     "d" (next)                            \
                                                                            \
    +                      __switch_canary_iparam                           \
    +                                                                       \
                         : /* reloaded segment registers */                 \
                            "memory");                                      \
     } while (0)
</code></pre>

<p>前面讲过当gcc检测到堆栈溢出的时候， 会调用glibc的stack_chk_fail函数， 但是当内核堆栈发生溢出的时候，不能调用glibc的函数，所以内核自己实现了一个stack_chk_fail函数：</p>

<p>kernel/panic.c</p>

<pre><code>    #ifdef CONFIG_CC_STACKPROTECTOR

    /*
     * Called when gcc's -fstack-protector feature is used, and
     * gcc detects corruption of the on-stack canary value
     */
    void __stack_chk_fail(void)
    {
        panic("stack-protector: Kernel stack is corrupted in: %p\n",
             __builtin_return_address(0));
    }
    EXPORT_SYMBOL(__stack_chk_fail);

    #endif
</code></pre>

<p>当内核堆栈发生溢出的时候，就会执行stack_chk_fail函数， 内核当机。</p>

<p>这就是这个补丁的原理，不懂的同学请参考：</p>

<p><a href="http://git.kernel.org/?p=linux/kernel/git/next/linux-next.git;a=commitdiff;h=60a5317ff0f42dd313094b88f809f63041568b08">http://git.kernel.org/?p=linux/kernel/git/next/linux-next.git;a=commitdiff;h=60a5317ff0f42dd313094b88f809f63041568b08</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Universal Build-ID]]></title>
    <link href="http://abcdxyzk.github.io/blog/2014/09/12/compiler-build-id/"/>
    <updated>2014-09-12T18:08:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2014/09/12/compiler-build-id</id>
    <content type="html"><![CDATA[<p><a href="http://fedoraproject.org/wiki/Summer_Coding_2010_ideas_-_Universal_Build-ID">http://fedoraproject.org/wiki/Summer_Coding_2010_ideas_-_Universal_Build-ID</a></p>

<h4>Summary</h4>

<p>  Build-IDs are currently being put into binaries, shared libraries, core files and related debuginfo files to uniquely identify the build a user or developer is working with. There are a couple of conventions in place to use this information to identify &ldquo;currently running&rdquo; or &ldquo;distro installed&rdquo; builds. This helps with identifying what was being run and match it to the corresponding package, sources and debuginfo for tools that want to help the user show what is going on (at the moment mostly when things break). We would like to extend this to a more universial approach, that helps people identify historical, local, non- or cross-distro or organisational builds. So that Build-IDs become useful outside the current &ldquo;static&rdquo; setup and retain information over time and across upgrades.</p>

<h3>Build-ID background</h3>

<p>  Build-IDs are unique identifiers of &ldquo;builds&rdquo;. A build is an executable, a shared library, the kernel, a module, etc. You can also find the build-id in a running process, a core file or a separate debuginfo file.</p>

<p>  The main idea behind Build-IDs is to make elf files &ldquo;self-identifying&rdquo;. This means that when you have a Build-ID it should uniquely identify a final executable or shared library. The default Build-ID calculation (done through ld &ndash;build-id, see the ld manual) calculates a sha1 hash (160 bits/20 bytes) based on all the ELF header bits and section contents in the file. Which means that it is unique among the set of meaningful contents for ELF files and identical when the output file would otherwise have been identical. GCC now passes &ndash;build-id to the linker by default.</p>

<p>  When an executable or shared library is loaded into memory the Build-ID will also be loaded into memory, a core dump of a process will also have the Build-IDs of the executable and the shared libraries embedded. And when separating debuginfo from the main executable or shared library into .debug files the original Build-ID will also be copied over. This means it is easy to match a core file or a running process to the original executable and shared library builds. And that matching those against the debuginfo files that provide more information for introspection and debugging should be trivial.</p>

<p>  Fedora has had full support for build-ids since Fedora Core 8: <a href="https://fedoraproject.org/wiki/Releases/FeatureBuildId">https://fedoraproject.org/wiki/Releases/FeatureBuildId</a></p>

<h4>Getting Build-IDs</h4>

<p>  A simple way to get the build-id(s) is through eu-unstrip (part of elfutils).</p>

<p>build-id from an executable, shared library or separate debuginfo file:<br/>
$ eu-unstrip -n -e &lt;exec|.sharedlib|.debug></p>

<p>build-ids of an executable and all shared libraries from a core file:<br/>
$ eu-unstrip -n &ndash;core <corefile></p>

<p>build-ids of an executable and all shared libraries of a running process:<br/>
$ eu-unstrip -n &ndash;pid <pid></p>

<p>build-id of the running kernel and all loaded modules:<br/>
$ eu-unstrip -n -k</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Oops打印Tainted信息]]></title>
    <link href="http://abcdxyzk.github.io/blog/2014/07/16/debug-oops/"/>
    <updated>2014-07-16T15:58:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2014/07/16/debug-oops</id>
    <content type="html"><![CDATA[<p>检查一下上面的Oops，看看Linux内核还有没有给我们留下其他的有用信息。
<code>
Oops: 0002 [#1]
</code>
* 这里面，0002表示Oops的错误代码（写错误，发生在内核空间），#1表示这个错误发生一次。</p>

<p>Oops的错误代码根据错误的原因会有不同的定义，本文中的例子可以参考下面的定义（如果发现自己遇到的Oops和下面无法对应的话，最好去内核代码里查找）：
<code>
 * error_code:
 *      bit 0 == 0 means no page found, 1 means protection fault
 *      bit 1 == 0 means read, 1 means write
 *      bit 2 == 0 means kernel, 1 means user-mode
 *      bit 3 == 0 means data, 1 means instruction
</code>
有时候，Oops还会打印出Tainted信息。这个信息用来指出内核是因何种原因被tainted（直译为“玷污”）。具体的定义如下：
<code>
  1: 'G' if all modules loaded have a GPL or compatible license, 'P' if any proprietary module has been loaded.  Modules without a MODULE_LICENSE or with a MODULE_LICENSE that is not recognised by insmod as GPL compatible are assumed to be proprietary.
  2: 'F' if any module was force loaded by "insmod -f", ' ' if all modules were loaded normally.
  3: 'S' if the oops occurred on an SMP kernel running on hardware that hasn't been certified as safe to run multiprocessor. Currently this occurs only on various Athlons that are not SMP capable.
  4: 'R' if a module was force unloaded by "rmmod -f", ' ' if all modules were unloaded normally.
  5: 'M' if any processor has reported a Machine Check Exception, ' ' if no Machine Check Exceptions have occurred.
  6: 'B' if a page-release function has found a bad page reference or some unexpected page flags.
  7: 'U' if a user or user application specifically requested that the Tainted flag be set, ' ' otherwise.
  8: 'D' if the kernel has died recently, i.e. there was an OOPS or BUG.
  9: 'A' if the ACPI table has been overridden.
 10: 'W' if a warning has previously been issued by the kernel. (Though some warnings may set more specific taint flags.)
 11: 'C' if a staging driver has been loaded.
 12: 'I' if the kernel is working around a severe bug in the platform firmware (BIOS or similar).
</code></p>
]]></content>
  </entry>
  
</feed>
