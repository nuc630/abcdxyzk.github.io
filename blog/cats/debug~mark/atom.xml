<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: debug~mark | kk Blog —— 通用基础]]></title>
  <link href="http://abcdxyzk.github.io/blog/cats/debug~mark/atom.xml" rel="self"/>
  <link href="http://abcdxyzk.github.io/"/>
  <updated>2016-05-11T20:15:01+08:00</updated>
  <id>http://abcdxyzk.github.io/</id>
  <author>
    <name><![CDATA[kk]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[CentOS 5.x安装新内核之后时钟混乱问题]]></title>
    <link href="http://abcdxyzk.github.io/blog/2016/01/06/debug-mark-rtc/"/>
    <updated>2016-01-06T11:08:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2016/01/06/debug-mark-rtc</id>
    <content type="html"><![CDATA[<pre><code>    $ ll /etc/rc.sysinit
    /etc/rc.sysinit -&gt; rc.d/rc.sysinit
</code></pre>

<p>el5在调用mkinitrd命令时，会将/dev/rtc生成好，放到initrd- x.x.x.img文件中。而el6的系统在 /etc/rc.sysinit的/sbin/start_udev 之前是有这两个文件，也没找到el6的系统是在哪里加的这两句。</p>

<p>el5可选的一个做法是：修改/etc/rc.sysinit,在/sbin/start_udev这行之前加入两行：
<code>
    mv /dev/rtc /dev/rtc0
    ln -sf rtc0 /dev/rtc
</code>
在/sbin/start_udev这行之后加入一行
<code>
    [ -x /sbin/hwclock ] &amp;&amp; /sbin/hwclock $CLOCKFLAGS
</code>
这样el5系统用18、32内核都没问题了。</p>

<p>el5试着将这两句改在/sbin/mkinitrd里修改，但不知道为什么改完后在执行到 /etc/rc.sysinit 时 /dev/rtc 这个软连接不见了。</p>

<p>或者直接将/dev/rtc改成254，0
<code>``
    diff --git a/mkinitrd b/mkinitrd
    index 5ddb909..dcba61d 100755
    --- a/mkinitrd
    +++ b/mkinitrd
    @@ -1708,7 +1708,14 @@ done
     mknod $MNTIMAGE/dev/tty c 5 0
     mknod $MNTIMAGE/dev/console c 5 1
     mknod $MNTIMAGE/dev/ptmx c 5 2
    -mknod $MNTIMAGE/dev/rtc c 10 135
    +
    +kernelval=</code>echo $kernel | awk -F &ldquo;[-|.]&rdquo; &lsquo;{print $1<em>65536+$2</em>256+$3}&rsquo;`
    +#echo &ldquo;kernel=$kernel kernelval=$kernelval&rdquo;
    +if [ $kernelval -lt 132640 ]; then
    +   mknod $MNTIMAGE/dev/rtc c 10 135
    +else
    +   mknod $MNTIMAGE/dev/rtc c 254 0
    +fi</p>

<pre><code> if [ "$(uname -m)" == "ia64" ]; then
     mknod $MNTIMAGE/dev/efirtc c 10 136
@@ -1911,8 +1918,16 @@ mknod /dev/systty c 4 0
 mknod /dev/tty c 5 0
 mknod /dev/console c 5 1
 mknod /dev/ptmx c 5 2
-mknod /dev/rtc c 10 135
 EOF
+
+kernelval=`echo $kernel | awk -F "[-|.]" '{print $1*65536+$2*256+$3}'`
+#echo "kernel=$kernel kernelval=$kernelval"
+if [ $kernelval -lt 132640 ]; then
+   emit "mknod /dev/rtc c 10 135"
+else
+   emit "mknod /dev/rtc c 254 0"
+fi
+
 if [ "$(uname -m)" == "ia64" ]; then
     emit "mknod /dev/efirtc c 10 136"
 fi
</code></pre>

<pre><code>然后重建img
</code></pre>

<pre><code>/sbin/new-kernel-pkg --package kernel --mkinitrd --depmod --install 2.6.32-XXX
</code></pre>

<pre><code>
------------------

http://www.csdn123.com/html/mycsdn20140110/59/59dd8c5f069a09bf9dc1785e19eb329f.html

CentOS在安装完新内核之后，每次重启之后时钟总是会发生一些变化，使得系统时钟不准确。在多操作系统的情况下（例如windows和 linux双系统），还可能会出现时区的偏差，而且无论如何设置，在重启之后都会恢复原样。如何解决这个问题还得从操作系统的时钟原理开始。

#### 1. 操作系统中的时钟

操作系统为实现其功能，必须知道当前外部世界的时间（年月日时分秒等）。为实现这一目的，计算机设计者在主板上设置了一个硬件时钟，由主板上的一块纽扣电池（Cell）供电，这个硬件时钟无论计算机电源是否接通都会不停的数秒，来计算当前时间。

操作系统在启动的时候，会调用一段程序来读取主板上的硬件时钟，并记录在操作系统的一个（或一组）变量中。自此之后，操作系统的时钟便脱离主板的硬件时钟，开始单独运行（操作系统时钟的运行是由时钟中断来驱动的，不同于主板上的时钟）。

无论做工多么精细，主板硬件时钟和由时钟中断维护的操作系统内的时钟多多少少会有一些误差。所以，操作系统在每次关闭的时候会调用另一段程序，将操作系统 内的时钟写到主板硬件时钟里（这样设计是不是说明时钟中断比主板硬件时钟更准确一些呢？）。类似的，当用户在操作系统内修改时钟之后，也不会立即写入主板 时钟，而是在关机的时候写入硬件时钟。

#### 2. 旧汤和新药的冲突
主板上的硬件时钟在Linux操作系统中呈现为一个设备，设备名称为rtc（Real Time Clock）。

使用旧的系统（如CentOS的2.6.18内核）编译新内核时，在调用mkinitrd命令时，会将/dev/rtc生成好，放到initrd- x.x.x.img文件中;而新的内核是自己生成/dev/rtc文件的，当kernel生成/dev/rtc时，发现系统内已经有了这个设备，于是就会 创建/dev/rtc0设备。这时hwclock程序仍然会读取rtc设备，就会造成设备读写失败。运行`hwclock --debug`命令可以看到如下输出：
</code></pre>

<pre><code>[root@localhost ~]# hwclock --debug
hwclock from util-linux-2.13-pre7
hwclock: Open of /dev/rtc failed, errno=19: No such device.
No usable clock interface found.
Cannot access the Hardware Clock via any known method.
</code></pre>

<pre><code>但是有的能够直接读写I/O，这样虽然/dev/rtc是错的，但还能正常运行
</code></pre>

<pre><code>[root@localhost ~]# hwclock --debug
hwclock from util-linux-2.13-pre7
hwclock: Open of /dev/rtc failed, errno=19: No such device.
Using direct I/O instructions to ISA clock.
.....
</code></pre>

<pre><code>
其实，对应这个问题，新版的hwclock已经做出了调整。新的hwclock会主动去寻找/dev/rtc0设备，来操作主板硬件时钟。于是，解决方法就出现了。

#### 3. 新汤配新药
既然内核这剂药已经换成了新的，那我们就把外围应用程序hwclock也换成新的。

从这里可以下载比较新的（不用最新的是因为最新的源码在旧版的CentOS上编译会出现错误）程序源码：http://now-code.com/download/util-linux-ng-2.17.tar.bz2 

如果需要更多版本的程序源码，请到这里下载：ftp://ftp.kernel.org/pub/linux/utils/。

下载完成之后，编译该程序：
</code></pre>

<pre><code>tar xfv util-linux-ng-2.17.tar.bz2
cd util-linux-ng-2.17
./configure
make
</code></pre>

<pre><code>编译完成之后，将生成的hwclock文件拷贝到指定位置即可：
</code></pre>

<pre><code>cp hwclock/hwclock /sbin/
</code></pre>

<p>```</p>

<p>之后，操作系统和主板的硬件时钟就可以同步起来了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ack loop]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/09/30/debug-loop_ack/"/>
    <updated>2015-09-30T15:32:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/09/30/debug-loop_ack</id>
    <content type="html"><![CDATA[<h4>patch</h4>

<pre><code>    commit 4fb17a6091674f469e8ac85dc770fbf9a9ba7cc8
    Author: Neal Cardwell &lt;ncardwell@google.com&gt;
    Date:   Fri Feb 6 16:04:41 2015 -0500

        tcp: mitigate ACK loops for connections as tcp_timewait_sock

        Ensure that in state FIN_WAIT2 or TIME_WAIT, where the connection is
        represented by a tcp_timewait_sock, we rate limit dupacks in response
        to incoming packets (a) with TCP timestamps that fail PAWS checks, or
        (b) with sequence numbers that are out of the acceptable window.

        We do not send a dupack in response to out-of-window packets if it has
        been less than sysctl_tcp_invalid_ratelimit (default 500ms) since we
        last sent a dupack in response to an out-of-window packet.

        Reported-by: Avery Fay &lt;avery@mixpanel.com&gt;
        Signed-off-by: Neal Cardwell &lt;ncardwell@google.com&gt;
        Signed-off-by: Yuchung Cheng &lt;ycheng@google.com&gt;
        Signed-off-by: Eric Dumazet &lt;edumazet@google.com&gt;
        Signed-off-by: David S. Miller &lt;davem@davemloft.net&gt;

    diff --git a/include/linux/tcp.h b/include/linux/tcp.h
    index 66d85a8..1a7adb4 100644
    --- a/include/linux/tcp.h
    +++ b/include/linux/tcp.h
    @@ -342,6 +342,10 @@ struct tcp_timewait_sock {
        u32           tw_rcv_wnd;
        u32           tw_ts_offset;
        u32           tw_ts_recent;
    +
    +   /* The time we sent the last out-of-window ACK: */
    +   u32           tw_last_oow_ack_time;
    +
        long              tw_ts_recent_stamp;
     #ifdef CONFIG_TCP_MD5SIG
        struct tcp_md5sig_key     *tw_md5_key;
    diff --git a/net/ipv4/tcp_minisocks.c b/net/ipv4/tcp_minisocks.c
    index 98a8405..dd11ac7 100644
    --- a/net/ipv4/tcp_minisocks.c
    +++ b/net/ipv4/tcp_minisocks.c
    @@ -58,6 +58,25 @@ static bool tcp_in_window(u32 seq, u32 end_seq, u32 s_win, u32 e_win)
        return seq == e_win &amp;&amp; seq == end_seq;
     }

    +static enum tcp_tw_status
    +tcp_timewait_check_oow_rate_limit(struct inet_timewait_sock *tw,
    +                 const struct sk_buff *skb, int mib_idx)
    +{
    +   struct tcp_timewait_sock *tcptw = tcp_twsk((struct sock *)tw);
    +
    +   if (!tcp_oow_rate_limited(twsk_net(tw), skb, mib_idx,
    +                 &amp;tcptw-&gt;tw_last_oow_ack_time)) {
    +       /* Send ACK. Note, we do not put the bucket,
    +        * it will be released by caller.
    +        */
    +       return TCP_TW_ACK;
    +   }
    +
    +   /* We are rate-limiting, so just release the tw sock and drop skb. */
    +   inet_twsk_put(tw);
    +   return TCP_TW_SUCCESS;
    +}
    +
     /*
      * * Main purpose of TIME-WAIT state is to close connection gracefully,
      *   when one of ends sits in LAST-ACK or CLOSING retransmitting FIN
    @@ -116,7 +135,8 @@ tcp_timewait_state_process(struct inet_timewait_sock *tw, struct sk_buff *skb,
                !tcp_in_window(TCP_SKB_CB(skb)-&gt;seq, TCP_SKB_CB(skb)-&gt;end_seq,
                       tcptw-&gt;tw_rcv_nxt,
                       tcptw-&gt;tw_rcv_nxt + tcptw-&gt;tw_rcv_wnd))
    -           return TCP_TW_ACK;
    +           return tcp_timewait_check_oow_rate_limit(
    +               tw, skb, LINUX_MIB_TCPACKSKIPPEDFINWAIT2);

            if (th-&gt;rst)
                goto kill;
    @@ -250,10 +270,8 @@ kill:
                inet_twsk_schedule(tw, &amp;tcp_death_row, TCP_TIMEWAIT_LEN,
                           TCP_TIMEWAIT_LEN);

    -       /* Send ACK. Note, we do not put the bucket,
    -        * it will be released by caller.
    -        */
    -       return TCP_TW_ACK;
    +       return tcp_timewait_check_oow_rate_limit(
    +           tw, skb, LINUX_MIB_TCPACKSKIPPEDTIMEWAIT);
        }
        inet_twsk_put(tw);
        return TCP_TW_SUCCESS;
    @@ -289,6 +307,7 @@ void tcp_time_wait(struct sock *sk, int state, int timeo)
            tcptw-&gt;tw_ts_recent = tp-&gt;rx_opt.ts_recent;
            tcptw-&gt;tw_ts_recent_stamp = tp-&gt;rx_opt.ts_recent_stamp;
            tcptw-&gt;tw_ts_offset = tp-&gt;tsoffset;
    +       tcptw-&gt;tw_last_oow_ack_time = 0;

     #if IS_ENABLED(CONFIG_IPV6)
            if (tw-&gt;tw_family == PF_INET6) {

    commit f2b2c582e82429270d5818fbabe653f4359d7024
    Author: Neal Cardwell &lt;ncardwell@google.com&gt;
    Date:   Fri Feb 6 16:04:40 2015 -0500

        tcp: mitigate ACK loops for connections as tcp_sock

        Ensure that in state ESTABLISHED, where the connection is represented
        by a tcp_sock, we rate limit dupacks in response to incoming packets
        (a) with TCP timestamps that fail PAWS checks, or (b) with sequence
        numbers or ACK numbers that are out of the acceptable window.

        We do not send a dupack in response to out-of-window packets if it has
        been less than sysctl_tcp_invalid_ratelimit (default 500ms) since we
        last sent a dupack in response to an out-of-window packet.

        There is already a similar (although global) rate-limiting mechanism
        for "challenge ACKs". When deciding whether to send a challence ACK,
        we first consult the new per-connection rate limit, and then the
        global rate limit.

        Reported-by: Avery Fay &lt;avery@mixpanel.com&gt;
        Signed-off-by: Neal Cardwell &lt;ncardwell@google.com&gt;
        Signed-off-by: Yuchung Cheng &lt;ycheng@google.com&gt;
        Signed-off-by: Eric Dumazet &lt;edumazet@google.com&gt;
        Signed-off-by: David S. Miller &lt;davem@davemloft.net&gt;

    diff --git a/include/linux/tcp.h b/include/linux/tcp.h
    index bcc828d..66d85a8 100644
    --- a/include/linux/tcp.h
    +++ b/include/linux/tcp.h
    @@ -153,6 +153,7 @@ struct tcp_sock {
        u32 snd_sml;    /* Last byte of the most recently transmitted small packet */
        u32 rcv_tstamp; /* timestamp of last received ACK (for keepalives) */
        u32 lsndtime;   /* timestamp of last sent data packet (for restart window) */
    +   u32 last_oow_ack_time;  /* timestamp of last out-of-window ACK */

        u32 tsoffset;   /* timestamp offset */

    diff --git a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c
    index 9401aa43..8fdd27b 100644
    --- a/net/ipv4/tcp_input.c
    +++ b/net/ipv4/tcp_input.c
    @@ -3322,13 +3322,22 @@ static int tcp_ack_update_window(struct sock *sk, const struct sk_buff *skb, u32
     }

     /* RFC 5961 7 [ACK Throttling] */
    -static void tcp_send_challenge_ack(struct sock *sk)
    +static void tcp_send_challenge_ack(struct sock *sk, const struct sk_buff *skb)
     {
        /* unprotected vars, we dont care of overwrites */
        static u32 challenge_timestamp;
        static unsigned int challenge_count;
    -   u32 now = jiffies / HZ;
    +   struct tcp_sock *tp = tcp_sk(sk);
    +   u32 now;
    +
    +   /* First check our per-socket dupack rate limit. */
    +   if (tcp_oow_rate_limited(sock_net(sk), skb,
    +                LINUX_MIB_TCPACKSKIPPEDCHALLENGE,
    +                &amp;tp-&gt;last_oow_ack_time))
    +       return;

    +   /* Then check the check host-wide RFC 5961 rate limit. */
    +   now = jiffies / HZ;
        if (now != challenge_timestamp) {
            challenge_timestamp = now;
            challenge_count = 0;
    @@ -3424,7 +3433,7 @@ static int tcp_ack(struct sock *sk, const struct sk_buff *skb, int flag)
        if (before(ack, prior_snd_una)) {
            /* RFC 5961 5.2 [Blind Data Injection Attack].[Mitigation] */
            if (before(ack, prior_snd_una - tp-&gt;max_window)) {
    -           tcp_send_challenge_ack(sk);
    +           tcp_send_challenge_ack(sk, skb);
                return -1;
            }
            goto old_ack;
    @@ -4993,7 +5002,10 @@ static bool tcp_validate_incoming(struct sock *sk, struct sk_buff *skb,
            tcp_paws_discard(sk, skb)) {
            if (!th-&gt;rst) {
                NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_PAWSESTABREJECTED);
    -           tcp_send_dupack(sk, skb);
    +           if (!tcp_oow_rate_limited(sock_net(sk), skb,
    +                         LINUX_MIB_TCPACKSKIPPEDPAWS,
    +                         &amp;tp-&gt;last_oow_ack_time))
    +               tcp_send_dupack(sk, skb);
                goto discard;
            }
            /* Reset is accepted even if it did not pass PAWS. */
    @@ -5010,7 +5022,10 @@ static bool tcp_validate_incoming(struct sock *sk, struct sk_buff *skb,
            if (!th-&gt;rst) {
                if (th-&gt;syn)
                    goto syn_challenge;
    -           tcp_send_dupack(sk, skb);
    +           if (!tcp_oow_rate_limited(sock_net(sk), skb,
    +                         LINUX_MIB_TCPACKSKIPPEDSEQ,
    +                         &amp;tp-&gt;last_oow_ack_time))
    +               tcp_send_dupack(sk, skb);
            }
            goto discard;
        }
    @@ -5026,7 +5041,7 @@ static bool tcp_validate_incoming(struct sock *sk, struct sk_buff *skb,
            if (TCP_SKB_CB(skb)-&gt;seq == tp-&gt;rcv_nxt)
                tcp_reset(sk);
            else
    -           tcp_send_challenge_ack(sk);
    +           tcp_send_challenge_ack(sk, skb);
            goto discard;
        }

    @@ -5040,7 +5055,7 @@ syn_challenge:
            if (syn_inerr)
                TCP_INC_STATS_BH(sock_net(sk), TCP_MIB_INERRS);
            NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPSYNCHALLENGE);
    -       tcp_send_challenge_ack(sk);
    +       tcp_send_challenge_ack(sk, skb);
            goto discard;
        }

    diff --git a/net/ipv4/tcp_minisocks.c b/net/ipv4/tcp_minisocks.c
    index 131aa49..98a8405 100644
    --- a/net/ipv4/tcp_minisocks.c
    +++ b/net/ipv4/tcp_minisocks.c
    @@ -467,6 +467,7 @@ struct sock *tcp_create_openreq_child(struct sock *sk, struct request_sock *req,
            tcp_enable_early_retrans(newtp);
            newtp-&gt;tlp_high_seq = 0;
            newtp-&gt;lsndtime = treq-&gt;snt_synack;
    +       newtp-&gt;last_oow_ack_time = 0;
            newtp-&gt;total_retrans = req-&gt;num_retrans;

            /* So many TCP implementations out there (incorrectly) count the

    commit a9b2c06dbef48ed31cff1764c5ce824829106f4f
    Author: Neal Cardwell &lt;ncardwell@google.com&gt;
    Date:   Fri Feb 6 16:04:39 2015 -0500

        tcp: mitigate ACK loops for connections as tcp_request_sock

        In the SYN_RECV state, where the TCP connection is represented by
        tcp_request_sock, we now rate-limit SYNACKs in response to a client's
        retransmitted SYNs: we do not send a SYNACK in response to client SYN
        if it has been less than sysctl_tcp_invalid_ratelimit (default 500ms)
        since we last sent a SYNACK in response to a client's retransmitted
        SYN.

        This allows the vast majority of legitimate client connections to
        proceed unimpeded, even for the most aggressive platforms, iOS and
        MacOS, which actually retransmit SYNs 1-second intervals for several
        times in a row. They use SYN RTO timeouts following the progression:
        1,1,1,1,1,2,4,8,16,32.

        Reported-by: Avery Fay &lt;avery@mixpanel.com&gt;
        Signed-off-by: Neal Cardwell &lt;ncardwell@google.com&gt;
        Signed-off-by: Yuchung Cheng &lt;ycheng@google.com&gt;
        Signed-off-by: Eric Dumazet &lt;edumazet@google.com&gt;
        Signed-off-by: David S. Miller &lt;davem@davemloft.net&gt;

    diff --git a/include/linux/tcp.h b/include/linux/tcp.h
    index 67309ec..bcc828d 100644
    --- a/include/linux/tcp.h
    +++ b/include/linux/tcp.h
    @@ -115,6 +115,7 @@ struct tcp_request_sock {
        u32             rcv_isn;
        u32             snt_isn;
        u32             snt_synack; /* synack sent time */
    +   u32             last_oow_ack_time; /* last SYNACK */
        u32             rcv_nxt; /* the ack # by SYNACK. For
                              * FastOpen it's the seq#
                              * after data-in-SYN.
    diff --git a/include/net/tcp.h b/include/net/tcp.h
    index b81f45c..da4196fb 100644
    --- a/include/net/tcp.h
    +++ b/include/net/tcp.h
    @@ -1145,6 +1145,7 @@ static inline void tcp_openreq_init(struct request_sock *req,
        tcp_rsk(req)-&gt;rcv_isn = TCP_SKB_CB(skb)-&gt;seq;
        tcp_rsk(req)-&gt;rcv_nxt = TCP_SKB_CB(skb)-&gt;seq + 1;
        tcp_rsk(req)-&gt;snt_synack = tcp_time_stamp;
    +   tcp_rsk(req)-&gt;last_oow_ack_time = 0;
        req-&gt;mss = rx_opt-&gt;mss_clamp;
        req-&gt;ts_recent = rx_opt-&gt;saw_tstamp ? rx_opt-&gt;rcv_tsval : 0;
        ireq-&gt;tstamp_ok = rx_opt-&gt;tstamp_ok;
    diff --git a/net/ipv4/tcp_minisocks.c b/net/ipv4/tcp_minisocks.c
    index bc9216d..131aa49 100644
    --- a/net/ipv4/tcp_minisocks.c
    +++ b/net/ipv4/tcp_minisocks.c
    @@ -605,7 +605,11 @@ struct sock *tcp_check_req(struct sock *sk, struct sk_buff *skb,
             * Reset timer after retransmitting SYNACK, similar to
             * the idea of fast retransmit in recovery.
             */
    -       if (!inet_rtx_syn_ack(sk, req))
    +       if (!tcp_oow_rate_limited(sock_net(sk), skb,
    +                     LINUX_MIB_TCPACKSKIPPEDSYNRECV,
    +                     &amp;tcp_rsk(req)-&gt;last_oow_ack_time) &amp;&amp;
    +
    +           !inet_rtx_syn_ack(sk, req))
                req-&gt;expires = min(TCP_TIMEOUT_INIT &lt;&lt; req-&gt;num_timeout,
                           TCP_RTO_MAX) + jiffies;
            return NULL;

    commit 032ee4236954eb214651cb9bfc1b38ffa8fd7a01
    Author: Neal Cardwell &lt;ncardwell@google.com&gt;
    Date:   Fri Feb 6 16:04:38 2015 -0500

        tcp: helpers to mitigate ACK loops by rate-limiting out-of-window dupacks

        Helpers for mitigating ACK loops by rate-limiting dupacks sent in
        response to incoming out-of-window packets.

        This patch includes:

        - rate-limiting logic
        - sysctl to control how often we allow dupacks to out-of-window packets
        - SNMP counter for cases where we rate-limited our dupack sending

        The rate-limiting logic in this patch decides to not send dupacks in
        response to out-of-window segments if (a) they are SYNs or pure ACKs
        and (b) the remote endpoint is sending them faster than the configured
        rate limit.

        We rate-limit our responses rather than blocking them entirely or
        resetting the connection, because legitimate connections can rely on
        dupacks in response to some out-of-window segments. For example, zero
        window probes are typically sent with a sequence number that is below
        the current window, and ZWPs thus expect to thus elicit a dupack in
        response.

        We allow dupacks in response to TCP segments with data, because these
        may be spurious retransmissions for which the remote endpoint wants to
        receive DSACKs. This is safe because segments with data can't
        realistically be part of ACK loops, which by their nature consist of
        each side sending pure/data-less ACKs to each other.

        The dupack interval is controlled by a new sysctl knob,
        tcp_invalid_ratelimit, given in milliseconds, in case an administrator
        needs to dial this upward in the face of a high-rate DoS attack. The
        name and units are chosen to be analogous to the existing analogous
        knob for ICMP, icmp_ratelimit.

        The default value for tcp_invalid_ratelimit is 500ms, which allows at
        most one such dupack per 500ms. This is chosen to be 2x faster than
        the 1-second minimum RTO interval allowed by RFC 6298 (section 2, rule
        2.4). We allow the extra 2x factor because network delay variations
        can cause packets sent at 1 second intervals to be compressed and
        arrive much closer.

        Reported-by: Avery Fay &lt;avery@mixpanel.com&gt;
        Signed-off-by: Neal Cardwell &lt;ncardwell@google.com&gt;
        Signed-off-by: Yuchung Cheng &lt;ycheng@google.com&gt;
        Signed-off-by: Eric Dumazet &lt;edumazet@google.com&gt;
        Signed-off-by: David S. Miller &lt;davem@davemloft.net&gt;

    diff --git a/Documentation/networking/ip-sysctl.txt b/Documentation/networking/ip-sysctl.txt
    index a5e4c81..1b8c964 100644
    --- a/Documentation/networking/ip-sysctl.txt
    +++ b/Documentation/networking/ip-sysctl.txt
    @@ -290,6 +290,28 @@ tcp_frto - INTEGER

        By default it's enabled with a non-zero value. 0 disables F-RTO.

    +tcp_invalid_ratelimit - INTEGER
    +   Limit the maximal rate for sending duplicate acknowledgments
    +   in response to incoming TCP packets that are for an existing
    +   connection but that are invalid due to any of these reasons:
    +
    +     (a) out-of-window sequence number,
    +     (b) out-of-window acknowledgment number, or
    +     (c) PAWS (Protection Against Wrapped Sequence numbers) check failure
    +
    +   This can help mitigate simple "ack loop" DoS attacks, wherein
    +   a buggy or malicious middlebox or man-in-the-middle can
    +   rewrite TCP header fields in manner that causes each endpoint
    +   to think that the other is sending invalid TCP segments, thus
    +   causing each side to send an unterminating stream of duplicate
    +   acknowledgments for invalid segments.
    +
    +   Using 0 disables rate-limiting of dupacks in response to
    +   invalid segments; otherwise this value specifies the minimal
    +   space between sending such dupacks, in milliseconds.
    +
    +   Default: 500 (milliseconds).
    +
     tcp_keepalive_time - INTEGER
        How often TCP sends out keepalive messages when keepalive is enabled.
        Default: 2hours.
    diff --git a/include/net/tcp.h b/include/net/tcp.h
    index 28e9bd3..b81f45c 100644
    --- a/include/net/tcp.h
    +++ b/include/net/tcp.h
    @@ -274,6 +274,7 @@ extern int sysctl_tcp_challenge_ack_limit;
     extern unsigned int sysctl_tcp_notsent_lowat;
     extern int sysctl_tcp_min_tso_segs;
     extern int sysctl_tcp_autocorking;
    +extern int sysctl_tcp_invalid_ratelimit;

     extern atomic_long_t tcp_memory_allocated;
     extern struct percpu_counter tcp_sockets_allocated;
    @@ -1236,6 +1237,37 @@ static inline bool tcp_paws_reject(const struct tcp_options_received *rx_opt,
        return true;
     }

    +/* Return true if we're currently rate-limiting out-of-window ACKs and
    + * thus shouldn't send a dupack right now. We rate-limit dupacks in
    + * response to out-of-window SYNs or ACKs to mitigate ACK loops or DoS
    + * attacks that send repeated SYNs or ACKs for the same connection. To
    + * do this, we do not send a duplicate SYNACK or ACK if the remote
    + * endpoint is sending out-of-window SYNs or pure ACKs at a high rate.
    + */
    +static inline bool tcp_oow_rate_limited(struct net *net,
    +                   const struct sk_buff *skb,
    +                   int mib_idx, u32 *last_oow_ack_time)
    +{
    +   /* Data packets without SYNs are not likely part of an ACK loop. */
    +   if ((TCP_SKB_CB(skb)-&gt;seq != TCP_SKB_CB(skb)-&gt;end_seq) &amp;&amp;
    +       !tcp_hdr(skb)-&gt;syn)
    +       goto not_rate_limited;
    +
    +   if (*last_oow_ack_time) {
    +       s32 elapsed = (s32)(tcp_time_stamp - *last_oow_ack_time);
    +
    +       if (0 &lt;= elapsed &amp;&amp; elapsed &lt; sysctl_tcp_invalid_ratelimit) {
    +           NET_INC_STATS_BH(net, mib_idx);
    +           return true;    /* rate-limited: don't send yet! */
    +       }
    +   }
    +
    +   *last_oow_ack_time = tcp_time_stamp;
    +
    +not_rate_limited:
    +   return false;   /* not rate-limited: go ahead, send dupack now! */
    +}
    +
     static inline void tcp_mib_init(struct net *net)
     {
        /* See RFC 2012 */
    diff --git a/include/uapi/linux/snmp.h b/include/uapi/linux/snmp.h
    index b222241..6a6fb74 100644
    --- a/include/uapi/linux/snmp.h
    +++ b/include/uapi/linux/snmp.h
    @@ -270,6 +270,12 @@ enum
        LINUX_MIB_TCPHYSTARTTRAINCWND,      /* TCPHystartTrainCwnd */
        LINUX_MIB_TCPHYSTARTDELAYDETECT,    /* TCPHystartDelayDetect */
        LINUX_MIB_TCPHYSTARTDELAYCWND,      /* TCPHystartDelayCwnd */
    +   LINUX_MIB_TCPACKSKIPPEDSYNRECV,     /* TCPACKSkippedSynRecv */
    +   LINUX_MIB_TCPACKSKIPPEDPAWS,        /* TCPACKSkippedPAWS */
    +   LINUX_MIB_TCPACKSKIPPEDSEQ,     /* TCPACKSkippedSeq */
    +   LINUX_MIB_TCPACKSKIPPEDFINWAIT2,    /* TCPACKSkippedFinWait2 */
    +   LINUX_MIB_TCPACKSKIPPEDTIMEWAIT,    /* TCPACKSkippedTimeWait */
    +   LINUX_MIB_TCPACKSKIPPEDCHALLENGE,   /* TCPACKSkippedChallenge */
        __LINUX_MIB_MAX
     };

    diff --git a/net/ipv4/proc.c b/net/ipv4/proc.c
    index 8f9cd20..d8953ef 100644
    --- a/net/ipv4/proc.c
    +++ b/net/ipv4/proc.c
    @@ -292,6 +292,12 @@ static const struct snmp_mib snmp4_net_list[] = {
        SNMP_MIB_ITEM("TCPHystartTrainCwnd", LINUX_MIB_TCPHYSTARTTRAINCWND),
        SNMP_MIB_ITEM("TCPHystartDelayDetect", LINUX_MIB_TCPHYSTARTDELAYDETECT),
        SNMP_MIB_ITEM("TCPHystartDelayCwnd", LINUX_MIB_TCPHYSTARTDELAYCWND),
    +   SNMP_MIB_ITEM("TCPACKSkippedSynRecv", LINUX_MIB_TCPACKSKIPPEDSYNRECV),
    +   SNMP_MIB_ITEM("TCPACKSkippedPAWS", LINUX_MIB_TCPACKSKIPPEDPAWS),
    +   SNMP_MIB_ITEM("TCPACKSkippedSeq", LINUX_MIB_TCPACKSKIPPEDSEQ),
    +   SNMP_MIB_ITEM("TCPACKSkippedFinWait2", LINUX_MIB_TCPACKSKIPPEDFINWAIT2),
    +   SNMP_MIB_ITEM("TCPACKSkippedTimeWait", LINUX_MIB_TCPACKSKIPPEDTIMEWAIT),
    +   SNMP_MIB_ITEM("TCPACKSkippedChallenge", LINUX_MIB_TCPACKSKIPPEDCHALLENGE),
        SNMP_MIB_SENTINEL
     };

    diff --git a/net/ipv4/sysctl_net_ipv4.c b/net/ipv4/sysctl_net_ipv4.c
    index e0ee384..82601a6 100644
    --- a/net/ipv4/sysctl_net_ipv4.c
    +++ b/net/ipv4/sysctl_net_ipv4.c
    @@ -729,6 +729,13 @@ static struct ctl_table ipv4_table[] = {
            .extra2     = &amp;one,
        },
        {
    +       .procname   = "tcp_invalid_ratelimit",
    +       .data       = &amp;sysctl_tcp_invalid_ratelimit,
    +       .maxlen     = sizeof(int),
    +       .mode       = 0644,
    +       .proc_handler   = proc_dointvec_ms_jiffies,
    +   },
    +   {
            .procname   = "icmp_msgs_per_sec",
            .data       = &amp;sysctl_icmp_msgs_per_sec,
            .maxlen     = sizeof(int),
    diff --git a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c
    index d3dfff7..9401aa43 100644
    --- a/net/ipv4/tcp_input.c
    +++ b/net/ipv4/tcp_input.c
    @@ -100,6 +100,7 @@ int sysctl_tcp_thin_dupack __read_mostly;

     int sysctl_tcp_moderate_rcvbuf __read_mostly = 1;
     int sysctl_tcp_early_retrans __read_mostly = 3;
    +int sysctl_tcp_invalid_ratelimit __read_mostly = HZ/2;

     #define FLAG_DATA      0x01 /* Incoming frame contained data.      */
     #define FLAG_WIN_UPDATE        0x02 /* Incoming ACK was a window update.   */
</code></pre>

<hr />

<h4>sample</h4>

<pre><code>    #define KMSG_COMPONENT "synflood"
    #define pr_fmt(fmt) KMSG_COMPONENT ": " fmt

    #include &lt;linux/module.h&gt;
    #include &lt;linux/kernel.h&gt;
    #include &lt;linux/ip.h&gt;
    #include &lt;linux/tcp.h&gt;
    #include &lt;linux/icmp.h&gt;
    #include &lt;linux/netfilter.h&gt;
    #include &lt;linux/netfilter_ipv4.h&gt;
    #include &lt;linux/netdevice.h&gt;

    #include &lt;net/ip.h&gt;
    #include &lt;net/tcp.h&gt;
    #include &lt;net/udp.h&gt;
    #include &lt;net/icmp.h&gt;

    __be16 cport = 80;
    char *selfip = NULL;

    module_param(cport, short, S_IRUGO);
    module_param(selfip, charp, S_IRUGO);

    void skbcsum(struct sk_buff *skb)
    {
        struct tcphdr *tcph;
        struct iphdr *iph;
        int iphl;
        int tcphl;
        int tcplen;

        iph = (struct iphdr *)skb-&gt;data;
        iphl = iph-&gt;ihl &lt;&lt; 2;
        tcph = (struct tcphdr *)(skb-&gt;data + iphl);
        tcphl = tcph-&gt;doff &lt;&lt; 2;

        iph-&gt;check = 0;
        iph-&gt;check = ip_fast_csum((unsigned char *)iph, iph-&gt;ihl);

        tcph-&gt;check    = 0;
        tcplen        = skb-&gt;len - (iph-&gt;ihl &lt;&lt; 2);
        if (skb-&gt;ip_summed == CHECKSUM_PARTIAL) {
            tcph-&gt;check = ~csum_tcpudp_magic(iph-&gt;saddr, iph-&gt;daddr,
                    tcplen, IPPROTO_TCP, 0);
            skb-&gt;csum_start    = skb_transport_header(skb) - skb-&gt;head;
            skb-&gt;csum_offset = offsetof(struct tcphdr, check);
        }
        else {
            skb-&gt;csum = 0;
            skb-&gt;csum = skb_checksum(skb, iph-&gt;ihl &lt;&lt; 2, tcplen, 0);
            tcph-&gt;check = csum_tcpudp_magic(iph-&gt;saddr, iph-&gt;daddr,
                    tcplen, IPPROTO_TCP, skb-&gt;csum);

        }
    }

    int pktcome = 0;
    int fincome = 0;
    static int check(__be32 ip, __be16 port, int syn, int fin)
    {
        if ((selfip == NULL || ip == in_aton(selfip)) &amp;&amp; ntohs(port) == cport) {
            if (syn) {
                pktcome = 0;
                fincome = 0;
            }
            pktcome ++;
            if (pktcome &gt; 30 || fincome == 3)
                return 1;
            fincome |= fin;
        }
        return 0;
    }

    static unsigned int local_in(unsigned int hooknum, 
        struct sk_buff *skb, const struct net_device *in, 
        const struct net_device *out, int (*okfn) (struct sk_buff *))
    {
        struct iphdr *iph;
        struct tcphdr *th;

        if (unlikely(skb-&gt;pkt_type != PACKET_HOST))
            goto exit;
        if (unlikely(skb-&gt;protocol != __constant_htons(ETH_P_IP)))
            goto exit;
        iph = (struct iphdr *)skb_network_header(skb);
        if (iph-&gt;protocol != IPPROTO_TCP)
            goto exit;
        if (unlikely(!pskb_may_pull(skb, iph-&gt;ihl * 4 + sizeof(struct tcphdr))))
            goto drop_out;
        skb_set_transport_header(skb, iph-&gt;ihl * 4);
        th = tcp_hdr(skb);
        if (check(iph-&gt;daddr, th-&gt;dest, th-&gt;syn, th-&gt;fin)) {
            skb-&gt;ip_summed = CHECKSUM_UNNECESSARY;
            th-&gt;seq = htonl(ntohl(th-&gt;seq) + 10000000);
        }
    exit:
        return NF_ACCEPT;
    drop_out:
        return NF_DROP;
    }

    static unsigned int local_out(unsigned int hooknum, 
        struct sk_buff *skb, const struct net_device *in, 
        const struct net_device *out, int (*okfn) (struct sk_buff *))
    {
        struct iphdr *iph;
        struct tcphdr *th;

        iph = (struct iphdr *)skb_network_header(skb);
        if (iph-&gt;protocol != IPPROTO_TCP)
            goto exit;
        if (unlikely(!pskb_may_pull(skb, iph-&gt;ihl * 4 + sizeof(struct tcphdr))))
            goto drop_out;
        skb_set_transport_header(skb, iph-&gt;ihl * 4);
        th = tcp_hdr(skb);
        if (check(iph-&gt;saddr, th-&gt;source, 0, (th-&gt;fin) &lt;&lt; 1)) {
            th-&gt;seq = htonl(ntohl(th-&gt;seq) + 10000000);
            skbcsum(skb);
        }
    exit:
        return NF_ACCEPT;
    drop_out:
        return NF_DROP;
    }

    static struct nf_hook_ops syndef_ops[] __read_mostly = {
        {
            .hook = local_in,
            .owner = THIS_MODULE,
            .pf = PF_INET,
            .hooknum = NF_INET_LOCAL_IN,
            .priority = 100,
        },
        {
            .hook = local_out,
            .owner = THIS_MODULE,
            .pf = PF_INET,
            .hooknum = NF_INET_LOCAL_OUT,
            .priority = 100,
        },

    };

    int __init loopack_init(void)
    {
        int ret;

        ret = nf_register_hooks(syndef_ops, ARRAY_SIZE(syndef_ops));
        if (ret &lt; 0) {
            pr_err("can't register hooks.\n");
            goto hooks_err;
        }

        pr_err("init success.\n");

    hooks_err:
        return ret;
    }

    void __exit loopack_exit(void)
    {
        nf_unregister_hooks(syndef_ops, ARRAY_SIZE(syndef_ops));

        pr_err("unload success.\n");
    }

    module_init(loopack_init);
    module_exit(loopack_exit);
    MODULE_AUTHOR("kk");
    MODULE_VERSION("1.0.0");
    MODULE_LICENSE("GPL");
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Machine Check Exception]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/09/02/debug-mce/"/>
    <updated>2015-09-02T16:53:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/09/02/debug-mce</id>
    <content type="html"><![CDATA[<p>dmesg显示
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
<span class='line-number'>202</span>
<span class='line-number'>203</span>
<span class='line-number'>204</span>
<span class='line-number'>205</span>
<span class='line-number'>206</span>
<span class='line-number'>207</span>
<span class='line-number'>208</span>
<span class='line-number'>209</span>
<span class='line-number'>210</span>
<span class='line-number'>211</span>
<span class='line-number'>212</span>
<span class='line-number'>213</span>
<span class='line-number'>214</span>
<span class='line-number'>215</span>
<span class='line-number'>216</span>
<span class='line-number'>217</span>
<span class='line-number'>218</span>
<span class='line-number'>219</span>
<span class='line-number'>220</span>
<span class='line-number'>221</span>
<span class='line-number'>222</span>
<span class='line-number'>223</span>
<span class='line-number'>224</span>
<span class='line-number'>225</span>
<span class='line-number'>226</span>
<span class='line-number'>227</span>
<span class='line-number'>228</span>
<span class='line-number'>229</span>
<span class='line-number'>230</span>
<span class='line-number'>231</span>
<span class='line-number'>232</span>
<span class='line-number'>233</span>
<span class='line-number'>234</span>
<span class='line-number'>235</span>
<span class='line-number'>236</span>
<span class='line-number'>237</span>
<span class='line-number'>238</span>
<span class='line-number'>239</span>
<span class='line-number'>240</span>
<span class='line-number'>241</span>
<span class='line-number'>242</span>
<span class='line-number'>243</span>
<span class='line-number'>244</span>
<span class='line-number'>245</span>
<span class='line-number'>246</span>
<span class='line-number'>247</span>
<span class='line-number'>248</span>
<span class='line-number'>249</span>
<span class='line-number'>250</span>
<span class='line-number'>251</span>
<span class='line-number'>252</span>
<span class='line-number'>253</span>
<span class='line-number'>254</span>
<span class='line-number'>255</span>
<span class='line-number'>256</span>
<span class='line-number'>257</span>
<span class='line-number'>258</span>
<span class='line-number'>259</span>
<span class='line-number'>260</span>
<span class='line-number'>261</span>
<span class='line-number'>262</span>
<span class='line-number'>263</span>
<span class='line-number'>264</span>
<span class='line-number'>265</span>
<span class='line-number'>266</span>
<span class='line-number'>267</span>
<span class='line-number'>268</span>
<span class='line-number'>269</span>
<span class='line-number'>270</span>
<span class='line-number'>271</span>
<span class='line-number'>272</span>
<span class='line-number'>273</span>
<span class='line-number'>274</span>
<span class='line-number'>275</span>
<span class='line-number'>276</span>
<span class='line-number'>277</span>
<span class='line-number'>278</span>
<span class='line-number'>279</span>
<span class='line-number'>280</span>
<span class='line-number'>281</span>
<span class='line-number'>282</span>
<span class='line-number'>283</span>
<span class='line-number'>284</span>
<span class='line-number'>285</span>
<span class='line-number'>286</span>
<span class='line-number'>287</span>
<span class='line-number'>288</span>
<span class='line-number'>289</span>
<span class='line-number'>290</span>
<span class='line-number'>291</span>
<span class='line-number'>292</span>
<span class='line-number'>293</span>
<span class='line-number'>294</span>
<span class='line-number'>295</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&hellip;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;sbridge: HANDLING MCE MEMORY ERROR
</span><span class='line'>CPU 0: Machine Check Exception: 0 Bank 5: 8c00004000010093
</span><span class='line'>TSC 0 ADDR 67081b300 MISC 2140040486 PROCESSOR 0:206d7 TIME 1441181676 SOCKET 0 APIC 0
</span><span class='line'>EDAC MC0: CE row 2, channel 0, label "CPU_SrcID#0_Channel#3_DIMM#0": 1 Unknown error(s): memory read on FATAL area : cpu=0 Err=0001:0093 (ch=3), addr= 0x67081b300 =&gt; socket=0, Channel=3(mask=8), rank=0
</span><span class='line'>
</span><span class='line'>...
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>保存4行log为mlog
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;# mcelog --ascii &lt; /tmp/mlog
</span><span class='line'>WARNING: with --dmi mcelog --ascii must run on the same machine with the
</span><span class='line'> same BIOS/memory configuration as where the machine check occurred.
</span><span class='line'>sbridge: HANDLING MCE MEMORY ERROR
</span><span class='line'>CPU 0: Machine Check Exception: 0 Bank 5: 8c00004000010093
</span><span class='line'>HARDWARE ERROR. This is *NOT* a software problem!
</span><span class='line'>Please contact your hardware vendor
</span><span class='line'>Wed Sep  2 16:14:36 2015
</span><span class='line'>CPU 0 BANK 5 MISC 2140040486 ADDR 67081b300
</span><span class='line'>STATUS 8c00004000010093 MCGSTATUS 0
</span><span class='line'>CPUID Vendor Intel Family 6 Model 45
</span><span class='line'>WARNING: SMBIOS data is often unreliable. Take with a grain of salt!
</span><span class='line'>&lt;24&gt; DIMM 1333 Mhz Res13 Width 72 Data Width 64 Size 16 GB
</span><span class='line'>Device Locator: Node0_Channel2_Dimm0
</span><span class='line'>Bank Locator: Node0_Bank0
</span><span class='line'>Manufacturer: Hynix Semiconducto
</span><span class='line'>Serial Number: 40743B5A
</span><span class='line'>Asset Tag: Dimm2_AssetTag
</span><span class='line'>Part Number: HMT42GR7BFR4A-PB
</span><span class='line'>TSC 0 ADDR 67081b300 MISC 2140040486 PROCESSOR 0:206d7 TIME 1441181676 SOCKET 0 APIC 0
</span><span class='line'>EDAC MC0: CE row 2, channel 0, label "CPU_SrcID#0_Channel#3_DIMM#0": 1 Unknown error(s): memory read on FATAL area : cpu=0 Err=0001:0093 (ch=3), addr = 0x67081b300 =&gt; socket=0, Channel=3(mask=8), rank=0
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>根据  
</span><span class='line'>Part Number: HMT42GR7BFR4A-PB  
</span><span class='line'>Serial Number: 40743B5A  
</span><span class='line'>
</span><span class='line'>在lshw中找相应硬件
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;...
</span><span class='line'>
</span><span class='line'> *-memory:0
</span><span class='line'>      description: System Memory
</span><span class='line'>      physical id: 2d
</span><span class='line'>      slot: System board or motherboard
</span><span class='line'>    *-bank:0
</span><span class='line'>         description: DIMM 1333 MHz (0.8 ns)
</span><span class='line'>         product: HMT42GR7BFR4A-PB
</span><span class='line'>         vendor: Hynix Semiconducto
</span><span class='line'>         physical id: 0
</span><span class='line'>         serial: 905D21AE
</span><span class='line'>         slot: Node0_Channel1_Dimm0
</span><span class='line'>         size: 16GiB
</span><span class='line'>         width: 64 bits
</span><span class='line'>         clock: 1333MHz (0.8ns)
</span><span class='line'>    *-bank:1
</span><span class='line'>         description: DIMM Synchronous [empty]
</span><span class='line'>         product: A1_Dimm1_PartNumber
</span><span class='line'>         vendor: Dimm1_Manufacturer
</span><span class='line'>         physical id: 1
</span><span class='line'>         serial: Dimm1_SerNum
</span><span class='line'>         slot: Node0_Channel1_Dimm1
</span><span class='line'>         width: 64 bits
</span><span class='line'>    *-bank:2
</span><span class='line'>         description: DIMM 1333 MHz (0.8 ns)
</span><span class='line'>         product: HMT42GR7BFR4A-PB
</span><span class='line'>         vendor: Hynix Semiconducto
</span><span class='line'>         physical id: 2
</span><span class='line'>         serial: 40743B5A
</span><span class='line'>         slot: Node0_Channel2_Dimm0
</span><span class='line'>         size: 16GiB
</span><span class='line'>         width: 64 bits
</span><span class='line'>         clock: 1333MHz (0.8ns)
</span><span class='line'>
</span><span class='line'>    ...
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;```&lt;/p&gt;
</span><span class='line'>]]&gt;&lt;/content&gt;
</span><span class='line'>  &lt;/entry&gt;
</span><span class='line'>  
</span><span class='line'>  &lt;entry&gt;
</span><span class='line'>&lt;title type="html"&gt;&lt;![CDATA[ixgbe两个合并包功能]]&gt;&lt;/title&gt;
</span><span class='line'>&lt;link href="http://abcdxyzk.github.io/blog/2015/08/21/debug-ixgbe/"/&gt;
</span><span class='line'>&lt;updated&gt;2015-08-21T15:29:00+08:00&lt;/updated&gt;
</span><span class='line'>&lt;id&gt;http://abcdxyzk.github.io/blog/2015/08/21/debug-ixgbe&lt;/id&gt;
</span><span class='line'>&lt;content type="html"&gt;&lt;![CDATA[&lt;p&gt;&lt;a href="http://downloadmirror.intel.com/22919/eng/README.txt"&gt;http://downloadmirror.intel.com/22919/eng/README.txt&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;a href="http://www.360doc.com/content/12/1101/17/9008018_245137867.shtml"&gt;http://www.360doc.com/content/12/1101/17/9008018_245137867.shtml&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;      LRO
</span><span class='line'>  ---
</span><span class='line'>  Large Receive Offload (LRO) is a technique for increasing inbound throughput
</span><span class='line'>  of high-bandwidth network connections by reducing CPU overhead. It works by
</span><span class='line'>  aggregating multiple incoming packets from a single stream into a larger 
</span><span class='line'>  buffer before they are passed higher up the networking stack, thus reducing
</span><span class='line'>  the number of packets that have to be processed. LRO combines multiple 
</span><span class='line'>  Ethernet frames into a single receive in the stack, thereby potentially 
</span><span class='line'>  decreasing CPU utilization for receives. 
</span><span class='line'>
</span><span class='line'>  IXGBE_NO_LRO is a compile time flag. The user can enable it at compile
</span><span class='line'>  time to remove support for LRO from the driver. The flag is used by adding 
</span><span class='line'>  CFLAGS_EXTRA="-DIXGBE_NO_LRO" to the make file when it's being compiled. 
</span><span class='line'>
</span><span class='line'>     make CFLAGS_EXTRA="-DIXGBE_NO_LRO" install
</span><span class='line'>
</span><span class='line'>  You can verify that the driver is using LRO by looking at these counters in 
</span><span class='line'>  ethtool:
</span><span class='line'>
</span><span class='line'>  lro_flushed - the total number of receives using LRO.
</span><span class='line'>  lro_aggregated - counts the total number of Ethernet packets that were combined.
</span><span class='line'>
</span><span class='line'>  NOTE: IPv6 and UDP are not supported by LRO.
</span><span class='line'>
</span><span class='line'>  HW RSC
</span><span class='line'>  ------
</span><span class='line'>  82599 and X540-based adapters support HW based receive side coalescing (RSC) 
</span><span class='line'>  which can merge multiple frames from the same IPv4 TCP/IP flow into a single
</span><span class='line'>  structure that can span one or more descriptors. It works similarly to SW
</span><span class='line'>  Large receive offload technique. By default HW RSC is enabled and SW LRO 
</span><span class='line'>  cannot be used for 82599 or X540-based adapters unless HW RSC is disabled.
</span><span class='line'>
</span><span class='line'>  IXGBE_NO_HW_RSC is a compile time flag. The user can enable it at compile 
</span><span class='line'>  time to remove support for HW RSC from the driver. The flag is used by adding 
</span><span class='line'>  CFLAGS_EXTRA="-DIXGBE_NO_HW_RSC" to the make file when it's being compiled.
</span><span class='line'>
</span><span class='line'>     make CFLAGS_EXTRA="-DIXGBE_NO_HW_RSC" install
</span><span class='line'>
</span><span class='line'>  You can verify that the driver is using HW RSC by looking at the counter in 
</span><span class='line'>  ethtool:
</span><span class='line'>
</span><span class='line'>     hw_rsc_count - counts the total number of Ethernet packets that were being
</span><span class='line'>     combined.
</span><span class='line'>
</span><span class='line'>    ...
</span><span class='line'>
</span><span class='line'>max_vfs
</span><span class='line'>-------
</span><span class='line'>Valid Range:   1-63
</span><span class='line'>Default Value: 0
</span><span class='line'>
</span><span class='line'>  If the value is greater than 0 it will also force the VMDq parameter to be 1
</span><span class='line'>  or more.
</span><span class='line'>
</span><span class='line'>  This parameter adds support for SR-IOV.  It causes the driver to spawn up to 
</span><span class='line'>  max_vfs worth of virtual function.  
</span><span class='line'>
</span><span class='line'>  NOTE: When either SR-IOV mode or VMDq mode is enabled, hardware VLAN 
</span><span class='line'>  filtering and VLAN tag stripping/insertion will remain enabled.
</span><span class='line'>  Please remove the old VLAN filter before the new VLAN filter is added.
</span><span class='line'>  For example, 
</span><span class='line'>
</span><span class='line'>    ip link set eth0 vf 0 vlan 100     // set vlan 100 for VF 0
</span><span class='line'>    ip link set eth0 vf 0 vlan 0       // Delete vlan 100 
</span><span class='line'>    ip link set eth0 vf 0 vlan 200     // set a new vlan 200 for VF 0
</span><span class='line'>
</span><span class='line'>The parameters for the driver are referenced by position.  So, if you have a 
</span><span class='line'>dual port 82599 or X540-based adapter and you want N virtual functions per 
</span><span class='line'>port, you must specify a number for each port with each parameter separated by
</span><span class='line'>a comma.
</span><span class='line'>
</span><span class='line'>For example:
</span><span class='line'>  modprobe ixgbe max_vfs=63,63
</span><span class='line'>
</span><span class='line'>NOTE: If both 82598 and 82599 or X540-based adapters are installed on the same 
</span><span class='line'>machine, you must be careful in loading the driver with the parameters. 
</span><span class='line'>Depending on system configuration, number of slots, etc. it's impossible to 
</span><span class='line'>predict in all cases where the positions would be on the command line and the 
</span><span class='line'>user will have to specify zero in those positions occupied by an 82598 port.
</span><span class='line'>
</span><span class='line'>With kernel 3.6, the driver supports the simultaneous usage of max_vfs and DCB 
</span><span class='line'>features, subject to the constraints described below. Prior to kernel 3.6, the 
</span><span class='line'>driver did not support the simultaneous operation of max_vfs &gt; 0 and the DCB 
</span><span class='line'>features (multiple traffic classes utilizing Priority Flow Control and Extended 
</span><span class='line'>Transmission Selection).
</span><span class='line'>
</span><span class='line'>When DCB is enabled, network traffic is transmitted and received through multiple 
</span><span class='line'>traffic classes (packet buffers in the NIC). The traffic is associated with a 
</span><span class='line'>specific class based on priority, which has a value of 0 through 7 used in the 
</span><span class='line'>VLAN tag. When SR-IOV is not enabled, each traffic class is associated with a set 
</span><span class='line'>of RX/TX descriptor queue pairs. The number of queue pairs for a given traffic 
</span><span class='line'>class depends on the hardware configuration. When SR-IOV is enabled, the descriptor 
</span><span class='line'>queue pairs are grouped into pools. The Physical Function (PF) and each Virtual 
</span><span class='line'>Function (VF) is allocated a pool of RX/TX descriptor queue pairs. When multiple 
</span><span class='line'>traffic classes are configured (for example, DCB is enabled), each pool contains a 
</span><span class='line'>queue pair from each traffic class. When a single traffic class is configured in 
</span><span class='line'>the hardware, the pools contain multiple queue pairs from the single traffic class.
</span><span class='line'>
</span><span class='line'>The number of VFs that can be allocated depends on the number of traffic classes 
</span><span class='line'>that can be enabled. The configurable number of traffic classes for each enabled 
</span><span class='line'>VF is as follows:
</span><span class='line'>
</span><span class='line'>  0 - 15 VFs = Up to 8 traffic classes, depending on device support
</span><span class='line'>
</span><span class='line'>  16 - 31 VFs = Up to 4 traffic classes
</span><span class='line'>
</span><span class='line'>  32 - 63 = 1 traffic class 
</span><span class='line'>
</span><span class='line'>When VFs are configured, the PF is allocated one pool as well. The PF supports 
</span><span class='line'>the DCB features with the constraint that each traffic class will only use a 
</span><span class='line'>single queue pair. When zero VFs are configured, the PF can support multiple 
</span><span class='line'>queue pairs per traffic class.
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;hr /&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;如果编译时disable了LRO，但没有disable RSC，可以用 ethtool -C eth2 rx-usecs 0 临时解决，或用 max_vfs=1 ？？？&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=680998"&gt;https://bugzilla.redhat.com/show_bug.cgi?id=680998&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>Chris Wright has this board in hands, here the comment from him:
</span><span class='line'>&gt; OK, disabling hw RSC with 'ethtool -C eth2 rx-usecs 0' (thanks
</span><span class='line'>&gt; Herbert!) is bringing this back for me (something like ~1800 Mb/s).
</span><span class='line'>&gt; This is roughly what booting with max_vfs=1 should have done, so I'm not
</span><span class='line'>&gt; sure why that didn't work.
</span><span class='line'>
</span><span class='line'>Note that disabling coalescing with ethtool results in better, 
</span><span class='line'>though still poor performance as would be expected since we're disabling coalescing. 
</span><span class='line'>The "max_vfs=1" parameter disables RSC as a side-effect and 
</span><span class='line'>doesn't have the performance hit that disabling interrupt coalescing on the NIC does. 
</span><span class='line'>In internal testing, "max_vfs=1" results in ~2.5x better performance than using ethtool.
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>]]&gt;&lt;/content&gt;
</span><span class='line'>  &lt;/entry&gt;
</span><span class='line'>  
</span><span class='line'>  &lt;entry&gt;
</span><span class='line'>&lt;title type="html"&gt;&lt;![CDATA[tcp_collapse do not copy headers]]&gt;&lt;/title&gt;
</span><span class='line'>&lt;link href="http://abcdxyzk.github.io/blog/2015/05/15/debug-mark-tcp_collapse-bug/"/&gt;
</span><span class='line'>&lt;updated&gt;2015-05-15T10:08:00+08:00&lt;/updated&gt;
</span><span class='line'>&lt;id&gt;http://abcdxyzk.github.io/blog/2015/05/15/debug-mark-tcp_collapse-bug&lt;/id&gt;
</span><span class='line'>&lt;content type="html"&gt;&lt;![CDATA[&lt;pre&gt;&lt;code&gt;    commit b3d6cb92fd190d720a01075c4d20cdca896663fc
</span><span class='line'>Author: Eric Dumazet &lt;edumazet@google.com&gt;
</span><span class='line'>Date:   Mon Sep 15 04:19:53 2014 -0700
</span><span class='line'>
</span><span class='line'>    tcp: do not copy headers in tcp_collapse()
</span><span class='line'>
</span><span class='line'>    tcp_collapse() wants to shrink skb so that the overhead is minimal.
</span><span class='line'>
</span><span class='line'>    Now we store tcp flags into TCP_SKB_CB(skb)-&gt;tcp_flags, we no longer
</span><span class='line'>    need to keep around full headers.
</span><span class='line'>    Whole available space is dedicated to the payload.
</span><span class='line'>
</span><span class='line'>    Signed-off-by: Eric Dumazet &lt;edumazet@google.com&gt;
</span><span class='line'>    Acked-by: Neal Cardwell &lt;ncardwell@google.com&gt;
</span><span class='line'>    Signed-off-by: David S. Miller &lt;davem@davemloft.net&gt;
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    diff --git a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c
</span><span class='line'>index 228bf0c..ea92f23 100644
</span><span class='line'>--- a/net/ipv4/tcp_input.c
</span><span class='line'>+++ b/net/ipv4/tcp_input.c
</span><span class='line'>@@ -4535,26 +4535,13 @@ restart:
</span><span class='line'>        return;
</span><span class='line'>
</span><span class='line'>    while (before(start, end)) {
</span><span class='line'>+       int copy = min_t(int, SKB_MAX_ORDER(0, 0), end - start);
</span><span class='line'>        struct sk_buff *nskb;
</span><span class='line'>-       unsigned int header = skb_headroom(skb);
</span><span class='line'>-       int copy = SKB_MAX_ORDER(header, 0);
</span><span class='line'>
</span><span class='line'>-       /* Too big header? This can happen with IPv6. */
</span><span class='line'>-       if (copy &lt; 0)
</span><span class='line'>-           return;
</span><span class='line'>-       if (end - start &lt; copy)
</span><span class='line'>-           copy = end - start;
</span><span class='line'>-       nskb = alloc_skb(copy + header, GFP_ATOMIC);
</span><span class='line'>+       nskb = alloc_skb(copy, GFP_ATOMIC);
</span><span class='line'>        if (!nskb)
</span><span class='line'>            return;
</span><span class='line'>
</span><span class='line'>-       skb_set_mac_header(nskb, skb_mac_header(skb) - skb-&gt;head);
</span><span class='line'>-       skb_set_network_header(nskb, (skb_network_header(skb) -
</span><span class='line'>-                         skb-&gt;head));
</span><span class='line'>-       skb_set_transport_header(nskb, (skb_transport_header(skb) -
</span><span class='line'>-                       skb-&gt;head));
</span><span class='line'>-       skb_reserve(nskb, header);
</span><span class='line'>-       memcpy(nskb-&gt;head, skb-&gt;head, header);
</span><span class='line'>        memcpy(nskb-&gt;cb, skb-&gt;cb, sizeof(skb-&gt;cb));
</span><span class='line'>        TCP_SKB_CB(nskb)-&gt;seq = TCP_SKB_CB(nskb)-&gt;end_seq = start;
</span><span class='line'>        __skb_queue_before(list, skb, nskb);
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;hr /&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;这个改进无形中修了一个BUG，但是这BUG正常情况下不会触发，除非我们对skb进行改动导致skb-&gt;data - skb-&gt;head = 4k时，如果此时内存紧张，且满足tcp_collapse合并条件才触发。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;BUG：
</span><span class='line'>tcp_collapse代码中有：</span></code></pre></td></tr></table></div></figure>
        while (before(start, end)) {
            struct sk_buff *nskb;
            unsigned int header = skb_headroom(skb);
            int copy = SKB_MAX_ORDER(header, 0);</p>

<pre><code>        /* Too big header? This can happen with IPv6. */
        if (copy &lt; 0) 
            return;

        ......

        /* Copy data, releasing collapsed skbs. */
        while (copy &gt; 0) { 
            int offset = start - TCP_SKB_CB(skb)-&gt;seq;
            int size = TCP_SKB_CB(skb)-&gt;end_seq - start;
</code></pre>

<pre><code>
也就是说如果header = 4k，那么copy = 0，那么会一直申请len=0的skb插入到receive队列，直到申请skb失败。这样就会造成tcp_recvmsg出错
</code></pre>

<pre><code>        skb_queue_walk(&amp;sk-&gt;sk_receive_queue, skb) {
            /* Now that we have two receive queues this
             * shouldn't happen.
             */
            if (WARN(before(*seq, TCP_SKB_CB(skb)-&gt;seq),
                 KERN_INFO "recvmsg bug: copied %X "
                       "seq %X rcvnxt %X fl %X\n", *seq,
                       TCP_SKB_CB(skb)-&gt;seq, tp-&gt;rcv_nxt,
                       flags))
                break;

            offset = *seq - TCP_SKB_CB(skb)-&gt;seq;
            if (tcp_hdr(skb)-&gt;syn)
                offset--;
            if (offset &lt; skb-&gt;len)
                goto found_ok_skb;
            if (tcp_hdr(skb)-&gt;fin)
                goto found_fin_ok;
            WARN(!(flags &amp; MSG_PEEK), KERN_INFO "recvmsg bug 2: "
                    "copied %X seq %X rcvnxt %X fl %X\n",
                    *seq, TCP_SKB_CB(skb)-&gt;seq,
                    tp-&gt;rcv_nxt, flags);
        }
</code></pre>

<pre><code>因为offset = 0, len = 0, if (offset &lt; skb-&gt;len)就不符合，报WARN。而且如果申请的len=0的skb过多，会导致一直在这里循环，因为WARN有打印堆栈，执行很慢。

错误如下：
</code></pre>

<pre><code>WARNING: at net/ipv4/tcp.c:1457 tcp_recvmsg+0x96a/0xc20() (Tainted: G   W  ---------------   )
Hardware name: PowerEdge R620
Modules linked in: sha256_generic ws_st_tcp_cubic(U) ws_st(U) autofs4 i2c_dev i2c_core bonding 8021q garp stp llc be2iscsi iscsi_boot_sysfs ib]
Pid: 6964, comm: squid Tainted: G        W  ---------------    2.6.32-358.6.1.x86_64 #1
Call Trace:
 [&lt;ffffffff8144f1ca&gt;] ? tcp_recvmsg+0x96a/0xc20
 [&lt;ffffffff8144f1ca&gt;] ? tcp_recvmsg+0x96a/0xc20
 [&lt;ffffffff81069aa8&gt;] ? warn_slowpath_common+0x98/0xc0
 [&lt;ffffffff81069bce&gt;] ? warn_slowpath_fmt+0x6e/0x70
 [&lt;ffffffff814ce08e&gt;] ? _spin_lock_bh+0x2e/0x40
 [&lt;ffffffff813fea53&gt;] ? skb_release_data+0xb3/0x100
 [&lt;ffffffff813feb56&gt;] ? __kfree_skb+0x46/0xa0
 [&lt;ffffffff8144f1ca&gt;] ? tcp_recvmsg+0x96a/0xc20
 [&lt;ffffffff813f93c7&gt;] ? sock_common_recvmsg+0x37/0x50
 [&lt;ffffffff813f6b05&gt;] ? sock_aio_read+0x185/0x190
 [&lt;ffffffff81171912&gt;] ? do_sync_read+0xf2/0x130
 [&lt;ffffffff81090e60&gt;] ? autoremove_wake_function+0x0/0x40
 [&lt;ffffffff811b4a2c&gt;] ? sys_epoll_wait+0x21c/0x3f0
 [&lt;ffffffff8120b3b6&gt;] ? security_file_permission+0x16/0x20
 [&lt;ffffffff81171bab&gt;] ? vfs_read+0x18b/0x1a0
 [&lt;ffffffff81172df5&gt;] ? sys_read+0x55/0x90
 [&lt;ffffffff8100af72&gt;] ? system_call_fastpath+0x16/0x1b
---[ end trace ef9663ba0fc61730 ]---
------------[ cut here ]------------
WARNING: at net/ipv4/tcp.c:1457 tcp_recvmsg+0x96a/0xc20() (Tainted: G        W  ---------------   )
Hardware name: PowerEdge R620
Modules linked in: sha256_generic ws_st_tcp_cubic(U) ws_st(U) autofs4 i2c_dev i2c_core bonding 8021q garp stp llc be2iscsi iscsi_boot_sysfs ib]
Pid: 6964, comm: squid Tainted: G        W  ---------------    2.6.32-358.6.1.x86_64 #1
Call Trace:
 [&lt;ffffffff8144f1ca&gt;] ? tcp_recvmsg+0x96a/0xc20
 [&lt;ffffffff8144f1ca&gt;] ? tcp_recvmsg+0x96a/0xc20
 [&lt;ffffffff81069aa8&gt;] ? warn_slowpath_common+0x98/0xc0
 [&lt;ffffffff81069bce&gt;] ? warn_slowpath_fmt+0x6e/0x70
 [&lt;ffffffff814ce08e&gt;] ? _spin_lock_bh+0x2e/0x40
 [&lt;ffffffff813fea53&gt;] ? skb_release_data+0xb3/0x100
 [&lt;ffffffff813feb56&gt;] ? __kfree_skb+0x46/0xa0
 [&lt;ffffffff8144f1ca&gt;] ? tcp_recvmsg+0x96a/0xc20
 [&lt;ffffffff813f93c7&gt;] ? sock_common_recvmsg+0x37/0x50
 [&lt;ffffffff813f6b05&gt;] ? sock_aio_read+0x185/0x190
 [&lt;ffffffff81171912&gt;] ? do_sync_read+0xf2/0x130
 [&lt;ffffffff81090e60&gt;] ? autoremove_wake_function+0x0/0x40
 [&lt;ffffffff811b4a2c&gt;] ? sys_epoll_wait+0x21c/0x3f0
 [&lt;ffffffff8120b3b6&gt;] ? security_file_permission+0x16/0x20
 [&lt;ffffffff81171bab&gt;] ? vfs_read+0x18b/0x1a0
 [&lt;ffffffff81172df5&gt;] ? sys_read+0x55/0x90
 [&lt;ffffffff8100af72&gt;] ? system_call_fastpath+0x16/0x1b
---[ end trace ef9663ba0fc61731 ]---
------------[ cut here ]------------

.......
</code></pre>

<pre><code>
如果skb申请的不多，很快就能看到tcp_cleanup_rbuf的WARN，仔细观察会发现，这里打印的end_seq和上面的seq是一样的。
</code></pre>

<pre><code>void tcp_cleanup_rbuf(struct sock *sk, int copied)
{
    struct tcp_sock *tp = tcp_sk(sk);
    int time_to_ack = 0;

#if TCP_DEBUG
    struct sk_buff *skb = skb_peek(&amp;sk-&gt;sk_receive_queue);

    WARN(skb &amp;&amp; !before(tp-&gt;copied_seq, TCP_SKB_CB(skb)-&gt;end_seq),
         KERN_INFO "cleanup rbuf bug: copied %X seq %X rcvnxt %X\n",
         tp-&gt;copied_seq, TCP_SKB_CB(skb)-&gt;end_seq, tp-&gt;rcv_nxt);
#endif
</code></pre>

<p>```</p>
]]></content>
  </entry>
  
</feed>
